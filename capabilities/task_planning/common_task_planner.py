import logging
import json
import re
import networkx as nx  # éœ€è¦å¼•å…¥ networkx
from typing import List, Dict, Optional, Any, Tuple
from .interface import ITaskPlanningCapability
from external.repositories.agent_structure_repo import AgentStructureRepository 

import logging
logger = logging.getLogger(__name__)

# å‡è®¾çš„å¤–éƒ¨ä¾èµ–ï¼Œå®é™…ä½¿ç”¨æ—¶è¯·æ›¿æ¢ä¸ºçœŸå®è·¯å¾„
# from repositories.structure import AgentStructureRepository 


##TODO:SCCçš„èŠ‚ç‚¹è¿˜æœ‰ä¸€äº›é—®é¢˜ï¼ŒåŒ…æ‹¬seqé¢„è®¾é¡ºåº
class CommonTaskPlanning(ITaskPlanningCapability):
    """
    ä»»åŠ¡è§„åˆ’å™¨ V2ï¼š
    1. è¯­ä¹‰å±‚ï¼šåŸºäº LLM å°†ç”¨æˆ·è‡ªç„¶è¯­è¨€æ‹†è§£ä¸ºåˆæ­¥æ„å›¾é“¾ (Agent vs MCP)ã€‚
    2. ç»“æ„å±‚ï¼šåŸºäº Neo4j çŸ¥è¯†å›¾è°±ï¼Œå‘ç°éšæ€§ä¾èµ–ï¼ˆSCCï¼‰ï¼Œå¯¹ Agent ä»»åŠ¡è¿›è¡ŒååŒè§„åˆ’ä¸æ‰©å……ã€‚
    """

    def __init__(self):
        super().__init__()
        self.logger = logging.getLogger(__name__)
        self.tree_manager = None
        self._llm = None
        self._structure_repo = None # ç”¨äºè¿æ¥ Neo4j

    def get_capability_type(self) -> str:
        return 'common_task_planning'

    def initialize(self, config: Dict[str, Any]) -> bool:
 
        from agents.tree.tree_manager import treeManager

        self.tree_manager = treeManager
        self._llm = None
        self._structure_repo = None
        return True

    def generate_execution_plan(
        self,
        agent_id: str,
        user_input: str,
        memory_context: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        [ä¸»å…¥å£] ç”Ÿæˆå®Œæ•´çš„æ‰§è¡Œè§„åˆ’é“¾ï¼ˆè¯­ä¹‰æ‹†è§£ -> ä¾èµ–æ‰©å……ï¼‰
        """
        try:
            # Phase 1: è¯­ä¹‰æ‹†è§£ï¼ˆæ³¨å…¥è®°å¿†ï¼‰
            # è®°å¿†åœ¨è¿™é‡Œå½±å“ï¼šAgent vs MCP çš„é€‰æ‹©ï¼Œä»¥åŠç¬¬ä¸€å±‚å‚æ•°çš„æå–
            base_plan = self._semantic_decomposition(agent_id, user_input, memory_context)
            if not base_plan:
                return []

            # Phase 2: ç»“æ„åŒ–æ‰©å……ï¼ˆé€ä¼ è®°å¿†ï¼‰
            # å°† memory_context æ‰“åŒ…è¿› contextï¼Œä¼ é€’ç»™ Neo4j ååŒè§„åˆ’å±‚
            expansion_context = {
                "main_intent": user_input,
                "global_memory": memory_context or ""  # <--- æ³¨å…¥ç‚¹
            }
            final_plan = self._expand_plan_with_dependencies(base_plan, context=expansion_context)
            
            self.logger.info(f"Final plan generated with {len(final_plan)} steps (expanded from {len(base_plan)}).")
            return final_plan

        except Exception as e:
            self.logger.error(f"Planning error: {e}", exc_info=True)
            return []



    def shutdown(self) -> None:
        """é‡Šæ”¾èµ„æºï¼Œé‡ç½®çŠ¶æ€"""
        self.tree_manager = None
        self._llm = None
        self._structure_repo = None
        logger.info("[CommonTaskPlanner] Shutdown completed")
    # =========================================================================
    # Phase 1: è¯­ä¹‰æ‹†è§£ (åŸæœ‰é€»è¾‘ä¿æŒä¸å˜ï¼Œæ”¹åä¸º internal method)
    # =========================================================================

    def _semantic_decomposition(self, agent_id: str, user_input: str, memory_context: str) -> List[Dict]:
        candidates = self._get_candidate_agents_info(agent_id)
        
        # æ„å»ºå¢å¼ºç‰ˆ Prompt
        prompt = self._build_enhanced_planning_prompt(user_input, memory_context, candidates)
        
        response = self._call_llm(prompt)
        return self._parse_llm_json(response)


    def _build_enhanced_planning_prompt(self, user_input, memory, agents):
        agents_str = json.dumps(agents, ensure_ascii=False, indent=2)
        memory_section = ""
        if memory:
            memory_section = f"""
### ğŸ§  é•¿æœŸè®°å¿†ä¸ç”¨æˆ·åå¥½
{memory}
*(è¯·åˆ©ç”¨ä¸Šè¿°è®°å¿†æ¥ä¼˜åŒ–å†³ç­–ã€‚ä¾‹å¦‚ï¼šå¦‚æœè®°å¿†æ˜¾ç¤ºç”¨æˆ·åå¥½"é’‰é’‰"ï¼Œåœ¨é‡åˆ°é€šçŸ¥ç±»ä»»åŠ¡æ—¶è¯·ä¼˜å…ˆé€‰æ‹©ç›¸å…³ MCP å·¥å…·ï¼Œæˆ–åœ¨ params ä¸­å¤‡æ³¨)*
"""

        return (
            f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ä»»åŠ¡ç¼–æ’ä¸“å®¶ã€‚è¯·ç»“åˆã€ç”¨æˆ·æŒ‡ä»¤ã€‘å’Œã€é•¿æœŸè®°å¿†ã€‘åˆ¶å®šæ‰§è¡Œè®¡åˆ’ã€‚

### å¯ç”¨å†…éƒ¨èŠ‚ç‚¹ (Agents)
{agents_str}
{memory_section}

### ç”¨æˆ·æŒ‡ä»¤
"{user_input}"

### è§„åˆ’è¦æ±‚
1. **è®°å¿†å¢å¼º**ï¼šå¦‚æœç”¨æˆ·æŒ‡ä»¤æ¨¡ç³Šï¼ˆå¦‚"è€æ ·å­"ã€"å‘ç»™é‚£ä¸ªäºº"ï¼‰ï¼Œè¯·æ ¹æ®ã€é•¿æœŸè®°å¿†ã€‘æ¨æ–­å…·ä½“å‚æ•°ã€‚
2. **èŠ‚ç‚¹é€‰æ‹©**ï¼šå†…éƒ¨èƒ½åŠ›èƒ½è¦†ç›–çš„é€‰ "AGENT"ï¼Œå¦åˆ™é€‰ "MCP"ã€‚
3. **è¾“å‡ºæ ¼å¼**ï¼šçº¯ JSON åˆ—è¡¨ã€‚

### ç¤ºä¾‹è¾“å‡º
[
  {{ "step": 1, "type": "AGENT", "executor": "doc_writer", "params": "æ ¼å¼ï¼šMarkdown (åŸºäºè®°å¿†åå¥½),"description": "å†™ä¸€ä»½ç”¨æˆ·æ–‡æ¡£" }},
  {{ "step": 2, "type": "MCP", "executor": "dingtalk_bot", "params": "æ¥æ”¶äººï¼šå°å¼  (åŸºäºè®°å¿†æ¨æ–­)", "description": "å‘é€é’‰é’‰æ¶ˆæ¯ç»™å°å¼ " }}
]
"""
        )
    # =========================================================================
    # Phase 2: ç»“æ„åŒ–ä¾èµ–æ‰©å…… (ä½ æä¾›çš„ SCC é€»è¾‘é›†æˆäºæ­¤)
    # =========================================================================

    def _expand_plan_with_dependencies(self, base_plan: List[Dict], context: Dict) -> List[Dict]:
        expanded_plan = []
        global_step_counter = 1

        for step in base_plan:
            if step.get('type') == 'MCP':
                step['step'] = global_step_counter
                expanded_plan.append(step)
                global_step_counter += 1
                continue

            if step.get('type') == 'AGENT':
                
                ##TODOï¼šæš‚æ—¶å…ˆå¿½ç•¥AGENT
                step['step'] = global_step_counter
                expanded_plan.append(step)
                global_step_counter += 1
                continue

                target_agent_id = step.get('executor')
                
                # æ„é€ å­ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿ global_memory è¢«ä¼ é€’
                sub_context = context.copy()
                sub_context['step_params'] = step.get('params', "")
                # ç¡®ä¿ context é‡Œæœ‰ global_memoryï¼Œå¦‚æœä¸Šå±‚æ²¡ä¼ åˆ™ä¸ºç©º
                if 'global_memory' not in sub_context:
                    sub_context['global_memory'] = "" 

                # è°ƒç”¨å­ä»»åŠ¡è§„åˆ’
                sub_tasks = self.plan_subtasks(target_agent_id, sub_context)

                if not sub_tasks:
                    step['step'] = global_step_counter
                    expanded_plan.append(step)
                    global_step_counter += 1
                else:
                    for sub in sub_tasks:
                        # å°†å­ä»»åŠ¡åŠ å…¥åˆ—è¡¨
                        expanded_plan.append({
                            "step": global_step_counter,
                            "type": "AGENT",
                            "executor": sub['node_id'],
                            "description": sub['intent_params'].get('description', 'Dependency Task'),
                            "params": sub['intent_params'].get('parameters', {}),
                            "is_dependency_expanded": True,
                            "original_parent": target_agent_id,
                            "reasoning": "Based on SCC structure & Memory" # å¯é€‰ï¼šå¢åŠ å¯è§£é‡Šæ€§å­—æ®µ
                        })
                        global_step_counter += 1
        return expanded_plan

    # =========================================================================
    # ä½ çš„æ ¸å¿ƒé€»è¾‘é›†æˆ: plan_subtasks & SCC Helpers
    # =========================================================================

    def plan_subtasks(self, parent_agent_id: str, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        è§„åˆ’å­ä»»åŠ¡åºåˆ—ï¼ˆç»“æ„å±‚ä¸»å…¥å£ï¼‰
        """
        # åªè¦èƒ½è¿ä¸Š Neo4j ä¸”æœ‰ LLMï¼Œå°±å°è¯•ååŒè§„åˆ’
        if self._structure_repo and self._llm:
            return self._plan_with_qwen_coordinated_scc(parent_agent_id, context)
        else:
            # é™çº§ï¼šä»…è¿”å›è‡ªå·±
            return [{"node_id": parent_agent_id, "intent_params": {"parameters": context.get('step_params')}}]

    def _plan_with_qwen_coordinated_scc(self, root_code: str, context: Dict[str, Any]) -> List[Dict[str, Any]]:
        # 1. è·å–å­å›¾ (å¸¦ SCC ID)
        nodes_data, edges_data = self._fetch_subgraph_with_scc_from_neo4j(
            root_code=root_code,
            threshold=context.get("influence_threshold", 0.3)
        )

        if not nodes_data:
            # æ²¡æœ‰æŸ¥åˆ°ä¾èµ–ï¼Œè¿”å›å•èŠ‚ç‚¹
            return [{"node_id": root_code, "intent_params": {"parameters": context.get('step_params')}}]

        # 2. æŒ‰ SCC åˆ†ç»„
        scc_groups = {}
        node_to_scc = {}
        node_properties = {}

        for node in nodes_data:
            nid = node["node_id"]
            props = node.get("properties", {})
            scc_id = props.get("scc_id", f"SCC_SINGLE_{nid}")
            node_properties[nid] = props
            node_to_scc[nid] = scc_id
            scc_groups.setdefault(scc_id, []).append(node)

        # 3. æ„å»ºå½±å“æ˜ å°„
        influence_map = {nid: [] for nid in node_properties}
        for edge in edges_data:
            u, v, w = edge["from"], edge["to"], edge.get("weight", 0.0)
            if u in influence_map: influence_map[u].append({"target": v, "strength": round(w, 3)})
            if v in influence_map: influence_map[v].append({"source": u, "strength": round(w, 3)})

        # 4. ååŒè§„åˆ’æ¯ä¸ª SCC ç»„
        all_task_details = {}
        for scc_id, group_nodes in scc_groups.items():
            if len(group_nodes) == 1:
                # å•ç‚¹è§„åˆ’
                detail = self._plan_single_node_with_qwen(group_nodes[0], context)
                all_task_details[group_nodes[0]["node_id"]] = detail
            else:
                # å¼ºè€¦åˆç»„ååŒè§„åˆ’
                group_plan = self._qwen_plan_scc_group(
                    scc_id=scc_id,
                    nodes=group_nodes,
                    influence_map=influence_map,
                    main_intent=context.get("main_intent", ""),
                    execution_memory=context.get("execution_memory", {})
                )
                all_task_details.update(group_plan)

        # 5. å…¨å±€æ‹“æ‰‘æ’åº (å¤„ç†ç¯)
        dg = nx.DiGraph()
        dg.add_nodes_from(node_properties.keys())
        for e in edges_data:
            dg.add_edge(e["from"], e["to"])
        
        try:
            global_order = list(nx.topological_sort(dg))
        except nx.NetworkXUnfeasible:
            global_order = self._topo_sort_with_scc(dg, node_to_scc)

        # 6. ç»„è£…ç»“æœ
        result = []
        for node_id in global_order:
            if node_id in all_task_details:
                result.append({
                    "node_id": node_id,
                    "intent_params": all_task_details[node_id]
                })
        return result

    def _fetch_subgraph_with_scc_from_neo4j(self, root_code: str, threshold: float = 0.3) -> Tuple[List, List]:
        """è¿æ¥ Neo4j Repository è·å–æ•°æ®"""
        if not self._structure_repo:
            return [], []
        try:
            # å‡è®¾ repo æœ‰æ­¤æ–¹æ³•
            result = self._structure_repo.get_influenced_subgraph_with_scc(
                root_code=root_code, threshold=threshold, max_hops=5
            )
            return result.get("nodes", []), result.get("edges", [])
        except Exception as e:
            self.logger.warning(f"Neo4j fetch failed: {e}")
            return [], []

    def _qwen_plan_scc_group(self, scc_id, nodes, influence_map, context) -> Dict:
        """
        å¯¹å¼ºè€¦åˆç»„ä»¶è¿›è¡ŒååŒè§„åˆ’ã€‚
        åœ¨æ­¤å¤„ï¼Œè®°å¿†çš„ä½œç”¨æ˜¯ï¼šç¡®ä¿æ‰€æœ‰å…³è”èŠ‚ç‚¹çš„å‚æ•°é£æ ¼ä¸€è‡´ä¸”ç¬¦åˆç”¨æˆ·ä¹ æƒ¯ã€‚
        """
        main_intent = context.get("main_intent", "")
        global_memory = context.get("global_memory", "") # <--- è·å–è®°å¿†
        node_ids = [n["node_id"] for n in nodes]

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªé«˜çº§ç³»ç»Ÿåè°ƒ AIã€‚æ­£åœ¨ä¸ºä¸€ä¸ªå¼ºè€¦åˆä»»åŠ¡ç»„ï¼ˆSCCï¼‰ç”Ÿæˆæ‰§è¡Œå‚æ•°ã€‚

## ç»„ ID: {scc_id}
## åŒ…å«èŠ‚ç‚¹: {json.dumps(node_ids, ensure_ascii=False)}
## ä¸»ä»»åŠ¡æ„å›¾: "{main_intent}"

## ğŸ§  ä¸Šä¸‹æ–‡è®°å¿†ä¸åå¥½
{global_memory if global_memory else "æ— å¯ç”¨è®°å¿†"}

## ä½ çš„ä»»åŠ¡
ä¸ºç»„å†…æ¯ä¸ªèŠ‚ç‚¹ç”Ÿæˆ `intent` å’Œ `parameters`ã€‚
**å…³é”®è¦æ±‚**ï¼š
1. **ä¸€è‡´æ€§**ï¼šç»„å†…èŠ‚ç‚¹çš„å‚æ•°å¿…é¡»äº’ç›¸å…¼å®¹ï¼ˆå¦‚ï¼šæ–‡ä»¶è·¯å¾„ã€ç‰ˆæœ¬å·ï¼‰ã€‚
2. **ä¸ªæ€§åŒ–**ï¼šå¦‚æœã€ä¸Šä¸‹æ–‡è®°å¿†ã€‘ä¸­æåˆ°äº†ç›¸å…³åå¥½ï¼ˆå¦‚ï¼šè¶…æ—¶æ—¶é—´è®¾ç½®ã€é»˜è®¤å®¡æ‰¹äººã€æ—¥å¿—çº§åˆ«ï¼‰ï¼Œè¯·åŠ¡å¿…åº”ç”¨åˆ°å‚æ•°ä¸­ã€‚

## è¾“å‡º (JSON)
{{
    "task_details": {{
        "node_a": {{ "intent": "...", "parameters": {{ ... }} }},
        "node_b": {{ "intent": "...", "parameters": {{ ... }} }}
    }}
}}
"""
        response = self._call_llm(prompt)
        data = self._parse_llm_json(response)
        if isinstance(data, dict) and "task_details" in data:
            return data["task_details"]
        return {n['node_id']: {"intent": "Coordinated Execution", "parameters": {}} for n in nodes}
    
    
    # å•èŠ‚ç‚¹è§„åˆ’ä¹ŸåŒæ ·æ³¨å…¥è®°å¿†
    def _plan_single_node_with_qwen(self, node, context):
        global_memory = context.get("global_memory", "")
        prompt = f"""
ä»»åŠ¡èŠ‚ç‚¹: {node['node_id']}
å½“å‰æ„å›¾: {context.get('main_intent')}
ç”¨æˆ·è®°å¿†: {global_memory}

è¯·ç”Ÿæˆè¯¥èŠ‚ç‚¹çš„æ‰§è¡Œå‚æ•° JSON (intent, parameters)ã€‚å‚è€ƒç”¨æˆ·è®°å¿†ä¸­çš„åå¥½ã€‚
"""
        res = self._call_llm(prompt)
        parsed = self._parse_llm_json(res)
        if isinstance(parsed, dict): return parsed
        return {"intent": f"Execute {node['node_id']}", "parameters": {}}
    

    def _topo_sort_with_scc(self, graph: nx.DiGraph, node_to_scc: Dict) -> List[str]:
        """åŒ…å«ç¯çš„æ‹“æ‰‘æ’åºç®—æ³• (ä¿ç•™ä½ çš„åŸé€»è¾‘)"""
        # ... (å®Œæ•´å¤ç”¨ä½ æä¾›çš„ _topo_sort_with_scc ä»£ç ) ...
        # ä¸ºäº†èŠ‚çœç¯‡å¹…ï¼Œè¿™é‡Œå‡è®¾å·²å®Œå…¨å¤åˆ¶ä½ çš„é€»è¾‘
        scc_graph = nx.DiGraph()
        scc_map = {}
        # æ ‡å‡†çš„ SCC ç¼©ç‚¹ + æ‹“æ‰‘æ’åºé€»è¾‘
        for idx, comp in enumerate(nx.strongly_connected_components(graph)):
            scc_id = f"COMP_{idx}"
            for node in comp: scc_map[node] = scc_id
            scc_graph.add_node(scc_id)
        for u, v in graph.edges():
            if scc_map[u] != scc_map[v]: scc_graph.add_edge(scc_map[u], scc_map[v])
        
        try:
            scc_order = list(nx.topological_sort(scc_graph))
        except:
            scc_order = list(scc_graph.nodes) # Fallback
            
        final_order = []
        # å°† SCC å†…éƒ¨èŠ‚ç‚¹ç®€å•å±•å¼€ (å› ä¸ºå†…éƒ¨æ˜¯ç¯ï¼Œé¡ºåºç›¸å¯¹ä¸é‡è¦æˆ–éœ€è¦é¢å¤–é€»è¾‘ï¼Œè¿™é‡Œç®€å•å¤„ç†)
        reverse_map = {}
        for n, sid in scc_map.items(): reverse_map.setdefault(sid, []).append(n)
        for sid in scc_order: final_order.extend(reverse_map.get(sid, []))
        return final_order

    # =========================================================================
    # Helpers (å¤ç”¨ä¹‹å‰çš„)
    # =========================================================================
    
    def _get_candidate_agents_info(self, agent_id: str) -> List[Dict]:
        """è·å–å­èŠ‚ç‚¹çš„è¯¦ç»†æè¿°ï¼Œä¾› LLM åˆ¤æ–­è¾¹ç•Œ"""
        if not self.tree_manager:
            return []
        
        children_ids = self.tree_manager.get_children(agent_id)
        info_list = []
        for cid in children_ids:
            meta = self.tree_manager.get_agent_meta(cid)
            if meta:
                info_list.append({
                    "id": cid,
                    "name": meta.get("name", "Unknown"),
                    "capabilities": meta.get("capability", []), # å‡è®¾è¿™æ˜¯ä¸€ä¸ªåˆ—è¡¨æˆ–æè¿°å­—ç¬¦ä¸²
                    "description": meta.get("description", "")
                })
        return info_list

    def _build_planning_prompt(self, user_input: str, memory_context: str, agents: List[Dict]) -> str:
        # åºåˆ—åŒ–å¯ç”¨ Agent åˆ—è¡¨
        agents_str = json.dumps(agents, ensure_ascii=False, indent=2)
        mem_str = memory_context if memory_context else "æ— "

        return (
            f"""
ä½ æ˜¯ä¸€ä¸ªé«˜çº§ä»»åŠ¡ç¼–æ’ä¸“å®¶ã€‚è¯·æ ¹æ®ã€ç”¨æˆ·æŒ‡ä»¤ã€‘åˆ¶å®šä¸€ä¸ªåˆ†æ­¥æ‰§è¡Œè®¡åˆ’ã€‚

### å¯ç”¨çš„å†…éƒ¨ Agent èŠ‚ç‚¹ï¼ˆInternal Agentsï¼‰
{agents_str}

### ä»»åŠ¡ä¸Šä¸‹æ–‡
{mem_str}

### ç”¨æˆ·æŒ‡ä»¤
"{user_input}"

### ä½ çš„å·¥ä½œè¦æ±‚
1. **æ‹†è§£ä»»åŠ¡**ï¼šå°†ç”¨æˆ·æŒ‡ä»¤æ‹†è§£ä¸ºé€»è¾‘é¡ºç•…çš„æ­¥éª¤é“¾ã€‚
2. **èƒ½åŠ›åŒ¹é…ï¼ˆå…³é”®ï¼‰**ï¼š
   - å¦‚æœæŸä¸ªæ­¥éª¤çš„ä»»åŠ¡å¯ä»¥é€šè¿‡ä¸Šè¿°ã€å†…éƒ¨ Agent èŠ‚ç‚¹ã€‘å®Œæˆï¼Œè¯·æ ‡è®° `type` ä¸º "AGENT"ï¼Œå¹¶å‡†ç¡®å¡«å…¥ `executor` (å³ agent id)ã€‚
   - å¦‚æœæŸä¸ªæ­¥éª¤çš„ä»»åŠ¡**ä¸åœ¨**ä¸Šè¿° Agent èƒ½åŠ›èŒƒå›´å†…ï¼ˆä¾‹å¦‚å‘é‚®ä»¶ã€æäº¤OAã€æ“ä½œç³»ç»Ÿæ–‡ä»¶ç­‰ï¼‰ï¼Œè¯·æ ‡è®° `type` ä¸º "MCP"ï¼Œå¹¶ç»™å‡ºä¸€ä¸ªå»ºè®®çš„å·¥å…·åç§°ä½œä¸º `executor`ã€‚
3. **å‚æ•°æå–**ï¼šä»æŒ‡ä»¤ä¸­æå–è¯¥æ­¥éª¤éœ€è¦çš„å…³é”®å‚æ•°ã€‚

### è¾“å‡ºæ ¼å¼
è¯·**ä»…**è¾“å‡ºä¸€ä¸ªæ ‡å‡†çš„ JSON åˆ—è¡¨ï¼Œä¸è¦åŒ…å« Markdown æ ‡è®°ï¼ˆå¦‚ ```jsonï¼‰ã€‚æ ¼å¼èŒƒä¾‹å¦‚ä¸‹ï¼š
[
    {{
        "step": 1,
        "description": "åˆ†ææ–‡æ¡£éœ€æ±‚",
        "type": "AGENT",
        "executor": "analyzer_agent",
        "params": "éœ€åˆ†æçš„æ•°æ®..."
    }},
    {{
        "step": 2,
        "description": "å‘é€é‚®ä»¶ç»™æŸäºº",
        "type": "MCP",
        "executor": "email_client",
        "params": "æ”¶ä»¶äºº: xxx"
    }}
]
"""
        )

    def _parse_llm_json(self, text: str) -> List[Dict]:
        """å¥å£®çš„ JSON è§£æå™¨ï¼Œå¤„ç† LLM å¯èƒ½è¿”å›çš„ä»£ç å—æ ‡è®°"""
        if not text:
            return []
        
        # 1. æ¸…æ´—ï¼šç§»é™¤ markdown ä»£ç å—æ ‡è®° ```json ... ```
        cleaned_text = re.sub(r'```json\s*', '', text, flags=re.IGNORECASE)
        cleaned_text = re.sub(r'```', '', cleaned_text)
        cleaned_text = cleaned_text.strip()
        
        try:
            data = json.loads(cleaned_text)
            if isinstance(data, list):
                return data
            # å¦‚æœ LLM åŒ…è£¹äº†ä¸€å±‚å­—å…¸
            if isinstance(data, dict) and 'plan' in data:
                return data['plan']
            return []
        except json.JSONDecodeError:
            self.logger.error(f"JSON Parse Error. Raw Text: {text}")
            # å°è¯•ç”¨æ­£åˆ™æå–åˆ—è¡¨éƒ¨åˆ†ï¼ˆå®¹é”™ï¼‰
            match = re.search(r'\[.*\]', cleaned_text, re.DOTALL)
            if match:
                try:
                    return json.loads(match.group())
                except:
                    pass
            return []

    def _call_llm(self, prompt: str) -> str:
        """ç»Ÿä¸€è°ƒç”¨ LLM"""
        # 1. å¦‚æœåˆå§‹åŒ–æ—¶æ³¨å…¥äº† clientï¼Œç›´æ¥ç”¨
        if self._llm:
            try:
                # å‡è®¾ _llm ä¹Ÿæ˜¯ ILLMCapability æ¥å£ï¼Œæ”¯æŒ generate(str)
                return self._llm.generate(prompt)
            except Exception:
                pass # å¤±è´¥åˆ™å°è¯•åŠ¨æ€åŠ è½½
        
        # 2. åŠ¨æ€åŠ è½½ (å…œåº•)
        try:
            from capabilities.llm.interface import ILLMCapability
            from capabilities.registry import capability_registry
            llm = capability_registry.get_capability("llm", ILLMCapability)
            if llm:
                return llm.generate(prompt)
        except ImportError:
            self.logger.error("LLM capability not found.")
        
        return ""