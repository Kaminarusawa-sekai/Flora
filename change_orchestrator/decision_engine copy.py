# decision_engine.py
import hashlib
import json
import uuid
from typing import Dict, List, Any, Tuple
from dataclasses import dataclass

import networkx as nx
from langchain.prompts import PromptTemplate
from langchain_community.llms import Tongyi  # âœ… ä¿®æ­£ï¼šä½¿ç”¨ Tongyi è€Œé Qwen
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

import faiss
import numpy as np

# å‡è®¾ä½ å°è£…çš„å›¾åµŒå…¥å·¥å…·ï¼ˆéœ€è‡ªè¡Œå®ç°æˆ–æ›¿æ¢ï¼‰
# from graphbrain import node2vec_embedding  # ç¤ºä¾‹å ä½ç¬¦
def node2vec_embedding(graph: nx.DiGraph) -> np.ndarray:
    """ä¸´æ—¶å ä½ï¼šè¿”å›éšæœºå‘é‡ï¼Œå®é™…åº”æ›¿æ¢ä¸ºçœŸå®å›¾åµŒå…¥"""
    dim = 64
    return np.random.randn(dim).astype(np.float32)


@dataclass
class ChangePattern:
    graph_hash: str
    graph_structure: Dict
    vector: np.ndarray
    coordination_strategy: Dict
    metadata: Dict


class IntelligentChangeEngine:
    """
    æ™ºèƒ½å˜æ›´å†³ç­–å¼•æ“
    æ”¯æŒï¼šæ€ç»´é“¾æ¨ç†ã€è‡ªæˆ‘ä¸€è‡´æ€§ã€å›¾ç¼“å­˜ã€æ¡ˆä¾‹æ£€ç´¢
    """

    def __init__(self, llm, vector_dim=64):
        self.llm = llm
        self.pattern_kb: Dict[str, ChangePattern] = {}  # å“ˆå¸Œ â†’ æ¡ˆä¾‹
        self.vector_index = faiss.IndexFlatL2(vector_dim)  # å‘é‡ç´¢å¼•
        self.vectors: List[np.ndarray] = []
        self.hash_to_idx: Dict[str, int] = {}
        self.graph_cache: Dict[str, nx.DiGraph] = {}
        self.step_chains = self._build_step_chains()  # âœ… æ›¿æ¢ä¸º LCEL é“¾

    def _build_step_chains(self):
        """æ„å»ºåˆ†æ­¥æ¨ç†é“¾ï¼ˆLCEL æ–¹å¼ï¼‰"""
        parser = StrOutputParser()
        return {
            "step1": (
                PromptTemplate.from_template(
                    "Step 1: åˆ†æå˜æ›´æºå¤´ '{main_flow}' åŠå…¶ç›´æ¥ä¾èµ–ã€‚\n"
                    "è¾“å…¥å‚æ•°ä¾èµ–: {inputs}\n"
                    "è¾“å‡ºå½±å“: {outputs}\n"
                    "è¯·åˆ—å‡ºæ‰€æœ‰ç›´æ¥å—å½±å“çš„æ¨¡å—åŠå…¶ä¾èµ–å…³ç³»ã€‚"
                )
                | self.llm
                | parser
            ),
            "step2": (
                PromptTemplate.from_template(
                    "Step 2: è¯†åˆ«å…³é”®ç“¶é¢ˆè·¯å¾„ï¼ˆå¦‚æœ€é•¿å»¶è¿Ÿé“¾ï¼‰ã€‚\n"
                    "å½“å‰ä¾èµ–å›¾: {graph_desc}\n"
                    "è¯·æŒ‡å‡ºå“ªæ¡è·¯å¾„æœ€å¯èƒ½æˆä¸ºæ€§èƒ½/ç¨³å®šæ€§ç“¶é¢ˆï¼Œå¹¶è§£é‡ŠåŸå› ã€‚"
                )
                | self.llm
                | parser
            ),
            "step3": (
                PromptTemplate.from_template(
                    "Step 3: æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¾ªç¯ä¾èµ–æˆ–èµ„æºç«äº‰ã€‚\n"
                    "å›¾ç»“æ„: {edges}\n"
                    "è¯·åˆ¤æ–­æ˜¯å¦å­˜åœ¨ç¯è·¯æˆ–å¹¶å‘å†²çªï¼Œè‹¥æœ‰ï¼Œè¯·æŒ‡å‡ºã€‚"
                )
                | self.llm
                | parser
            ),
            "step4": (
                PromptTemplate.from_template(
                    "Step 4: å¯¹æ¯ä¸ªå—å½±å“æ¨¡å—æå‡ºå‚æ•°è°ƒæ•´å»ºè®®ã€‚\n"
                    "æ¨¡å—: {modules}\n"
                    "å½“å‰é…ç½®: {configs}\n"
                    "è¯·ä¸ºæ¯ä¸ªæ¨¡å—å»ºè®®åˆç†çš„å‚æ•°è°ƒæ•´ï¼ˆå¦‚è¶…æ—¶ã€é‡è¯•ã€å¹¶å‘æ•°ï¼‰ã€‚"
                )
                | self.llm
                | parser
            ),
            "step5": (
                PromptTemplate.from_template(
                    "Step 5: éªŒè¯æ•´ä½“æ˜¯å¦æ»¡è¶³ç¨³å®šæ€§çº¦æŸã€‚\n"
                    "ç³»ç»Ÿè¦æ±‚: {constraints}\n"
                    "å½“å‰æ–¹æ¡ˆ: {proposed}\n"
                    "è¯·è¯„ä¼°é£é™©å¹¶æå‡ºæ”¹è¿›å»ºè®®ã€‚"
                )
                | self.llm
                | parser
            ),
            "step6": (
                PromptTemplate.from_template(
                    "Step 6: ç»¼åˆä»¥ä¸Šåˆ†æï¼Œè¾“å‡ºæœ€ç»ˆåè°ƒæ–¹æ¡ˆã€‚\n"
                    "è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºï¼š{ 'execution_order': [...], 'parallel_groups': [...], 'param_adjustments': { ... } }"
                )
                | self.llm
                | parser
            ),
        }

    def _graph_to_hash(self, graph: nx.DiGraph) -> str:
        """å¯¹å›¾ç»“æ„åšæ ‡å‡†åŒ–å“ˆå¸Œ"""
        nodes = sorted(graph.nodes)
        edges = sorted((u, v) for u, v in graph.edges)
        data = json.dumps({"nodes": nodes, "edges": edges}, sort_keys=True)
        return hashlib.sha256(data.encode()).hexdigest()

    def _build_influence_graph(self, req: Dict) -> nx.DiGraph:
        """æ„å»ºå½±å“å›¾ï¼ˆå¯å¢é‡æ›´æ–°ï¼‰"""
        G = nx.DiGraph()

        main = req["main_affected_flow"]
        G.add_node(main, type="root", impact=1.0)

        interfaces = req["flow_interfaces"]
        for item in req["impacted_flows"]:
            flow = item["flow"]
            impact = item["impact_strength"]
            G.add_node(flow, impact=impact)
            # æ·»åŠ  I/O ä¾èµ–è¾¹
            if flow in interfaces:
                inputs = interfaces[flow].get("inputs", [])
                for inp in inputs:
                    source_flow = self._infer_source_flow(inp, req)
                    if source_flow and source_flow in G:
                        G.add_edge(source_flow, flow, type="data_dependency")

        return G

    def _infer_source_flow(self, param: str, req: Dict) -> str:
        """æ ¹æ®å‚æ•°ååæ¨æ¥æºæµç¨‹ï¼ˆå¯å¢å¼ºä¸ºæ­£åˆ™æˆ–å…ƒæ•°æ®ï¼‰"""
        for flow_name, iface in req["flow_interfaces"].items():
            if param in iface.get("outputs", []):
                return flow_name
        return None

    def _get_or_create_vector(self, graph: nx.DiGraph) -> np.ndarray:
        """ç”Ÿæˆå›¾åµŒå…¥å‘é‡ï¼ˆç®€åŒ–ç‰ˆï¼šNode2Vecï¼‰"""
        # å®é™…å¯ç”¨ node2vecã€Graph2Vec ç­‰
        return node2vec_embedding(graph)  # è¿”å› shape=(dim,)

    def _retrieve_similar_case(self, graph: nx.DiGraph, threshold=0.9) -> ChangePattern:
        """å‘é‡æ£€ç´¢æœ€ç›¸ä¼¼çš„å†å²æ¡ˆä¾‹"""
        vec = self._get_or_create_vector(graph).reshape(1, -1)
        if self.vector_index.ntotal == 0:
            return None

        dists, indices = self.vector_index.search(vec, k=1)
        if dists[0][0] < (1 - threshold):  # è·ç¦»è¶Šå°è¶Šç›¸ä¼¼
            idx = indices[0][0]
            for h, i in self.hash_to_idx.items():
                if i == idx:
                    return self.pattern_kb[h]
        return None

    async def _run_cot_reasoning(self, req: Dict, graph: nx.DiGraph) -> List[Dict]:
        """è¿è¡Œå¤šè·¯å¾„æ€ç»´é“¾æ¨ç†ï¼ˆSelf-Consistencyï¼‰"""
        candidates = []
        for _ in range(3):  # 3 æ¡ç‹¬ç«‹æ¨ç†è·¯å¾„
            strategy = {}
            for step_name, chain in self.step_chains.items():
                input_data = self._build_step_input(step_name, req, graph, strategy)
                output = await chain.ainvoke(input_data)  # âœ… æ”¯æŒå¼‚æ­¥è°ƒç”¨
                # è§£æ step6 çš„æœ€ç»ˆè¾“å‡º
                if step_name == "step6":
                    strategy = self._parse_json(output)
            candidates.append(strategy)
        return candidates

    def _build_step_input(self, step: str, req: Dict, graph: nx.DiGraph, strategy: Dict) -> Dict:
        """æ„å»ºæ¯ä¸€æ­¥çš„è¾“å…¥"""
        if step == "step1":
            iface = req["flow_interfaces"].get(req["main_affected_flow"], {})
            return {
                "main_flow": req["main_affected_flow"],
                "inputs": ", ".join(iface.get("inputs", [])),
                "outputs": ", ".join(iface.get("outputs", []))
            }
        elif step == "step2":
            return {"graph_desc": str([(u, v) for u, v in graph.edges])}
        elif step == "step3":
            return {"edges": str([(u, v) for u, v in graph.edges])}
        elif step == "step4":
            return {
                "modules": ", ".join(graph.nodes),
                "configs": json.dumps({n: "default" for n in graph.nodes})
            }
        elif step == "step5":
            return {
                "constraints": "ä½å»¶è¿Ÿã€æ— æ­»é”ã€é«˜å¯ç”¨",
                "proposed": json.dumps(strategy)
            }
        elif step == "step6":
            return {"proposed": json.dumps(strategy)}
        return {}

    def _parse_json(self, text: str) -> Dict:
        import re
        match = re.search(r'\{.*\}', text, re.DOTALL)
        if match:
            try:
                return json.loads(match.group())
            except:
                pass
        return {}

    def _self_consensus(self, candidates: List[Dict]) -> Dict:
        """è‡ªæˆ‘ä¸€è‡´æ€§ï¼šå–å‡ºç°æ¬¡æ•°æœ€å¤šçš„å­—æ®µç»„åˆï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        from collections import Counter
        orders = tuple(sorted(c.get("execution_order", [])) for c in candidates)
        best_order = Counter(orders).most_common(1)[0][0]

        # åˆå¹¶å‚æ•°è°ƒæ•´
        param_adj = {}
        for c in candidates:
            for k, v in c.get("param_adjustments", {}).items():
                param_adj.setdefault(k, []).append(v)
        final_param = {k: max(v, key=v.count) for k, v in param_adj.items()}  # æŠ•ç¥¨å–ä¼—æ•°

        return {
            "execution_order": list(best_order),
            "parallel_groups": [],  # å¯è¿›ä¸€æ­¥åˆ†æ
            "param_adjustments": final_param
        }

    async def run(self, change_request: Dict) -> Dict:
        """ä¸»å…¥å£ï¼ˆå¼‚æ­¥ï¼‰"""
        # Step 1: æ„å»ºå½±å“å­å›¾
        G = self._build_influence_graph(change_request)
        graph_hash = self._graph_to_hash(G)

        # Step 2: æ£€æŸ¥ç¼“å­˜ & å‘é‡æ£€ç´¢
        cached_case = self._retrieve_similar_case(G)
        if cached_case and cached_case.graph_hash == graph_hash:
            print(f"ğŸ” å‘½ä¸­å®Œå…¨åŒ¹é…ç¼“å­˜: {graph_hash[:8]}")
            return {
                "change_id": str(uuid.uuid4()),
                "strategy": cached_case.coordination_strategy,
                "source": "cache_exact",
                "graph_hash": graph_hash
            }

        if cached_case:
            print(f"ğŸ¯ å‘½ä¸­ç›¸ä¼¼æ¡ˆä¾‹: {cached_case.graph_hash[:8]}ï¼Œè¿›è¡Œå¾®è°ƒ")
            return {
                "change_id": str(uuid.uuid4()),
                "strategy": cached_case.coordination_strategy,
                "source": "cache_similar",
                "graph_hash": graph_hash
            }

        # Step 3: å¯åŠ¨å¤šè·¯å¾„æ¨ç†
        print("ğŸ§  å¯åŠ¨å¤šè·¯å¾„æ€ç»´é“¾æ¨ç†...")
        candidates = await self._run_cot_reasoning(change_request, G)
        final_strategy = self._self_consensus(candidates)

        # Step 4: ç¼“å­˜æ–°ç»“æœ
        vector = self._get_or_create_vector(G)
        idx = len(self.vectors)
        self.vector_index.add(vector.reshape(1, -1))
        self.vectors.append(vector)
        self.hash_to_idx[graph_hash] = idx

        self.pattern_kb[graph_hash] = ChangePattern(
            graph_hash=graph_hash,
            graph_structure={},
            vector=vector,
            coordination_strategy=final_strategy,
            metadata={"request_intent": change_request["proposed_change"]["intent"]}
        )

        return {
            "change_id": str(uuid.uuid4()),
            "strategy": final_strategy,
            "source": "llm_reasoning",
            "graph_hash": graph_hash,
            "candidate_count": len(candidates)
        }