# decision_engine.py
import hashlib
import json
import uuid
from typing import Dict, List, Any, Tuple
from dataclasses import dataclass

import networkx as nx
from langchain.prompts import PromptTemplate
from langchain_community.llms import Tongyi  # âœ… ä¿®æ­£ï¼šä½¿ç”¨ Tongyi è€Œé Qwen
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

# import faiss
import numpy as np


import asyncio
from collections import Counter, defaultdict
import traceback

# å‡è®¾ä½ å°è£…çš„å›¾åµŒå…¥å·¥å…·ï¼ˆéœ€è‡ªè¡Œå®ç°æˆ–æ›¿æ¢ï¼‰
# from graphbrain import node2vec_embedding  # ç¤ºä¾‹å ä½ç¬¦
# def node2vec_embedding(graph: nx.DiGraph) -> np.ndarray:
#     """ä¸´æ—¶å ä½ï¼šè¿”å›éšæœºå‘é‡ï¼Œå®é™…åº”æ›¿æ¢ä¸ºçœŸå®å›¾åµŒå…¥"""
#     dim = 64
#     return np.random.randn(dim).astype(np.float32)


@dataclass
class ChangePattern:
    graph_hash: str
    graph_structure: Dict
    vector: np.ndarray
    coordination_strategy: Dict
    metadata: Dict


class IntelligentChangeEngine:
    """
    æ™ºèƒ½å˜æ›´å†³ç­–å¼•æ“
    æ”¯æŒï¼šæ€ç»´é“¾æ¨ç†ã€è‡ªæˆ‘ä¸€è‡´æ€§ã€å›¾ç¼“å­˜ã€æ¡ˆä¾‹æ£€ç´¢
    """

    def __init__(self, llm, vector_dim=64):
        if not llm:
            llm = Tongyi(model_name="qwen-max")
        else:
            self.llm = llm
        
        self.pattern_kb: Dict[str, ChangePattern] = {}  # å“ˆå¸Œ â†’ æ¡ˆä¾‹
        # self.vector_index = faiss.IndexFlatL2(vector_dim)  # å‘é‡ç´¢å¼•
        self.vectors: List[np.ndarray] = []
        self.hash_to_idx: Dict[str, int] = {}
        self.graph_cache: Dict[str, nx.DiGraph] = {}
        # self.step_chains = self._build_step_chains()  # âœ… æ›¿æ¢ä¸º LCEL é“¾

    def _parse_json_output(self, text: str) -> Dict:
        """é²æ£’æ€§ JSON è§£æ"""
        import re
        match = re.search(r'\{.*\}', text, re.DOTALL)
        if not match:
            return self._get_fallback_output()

        try:
            parsed = json.loads(match.group())
            # ç¡®ä¿ç»“æ„å®Œæ•´
            parsed.setdefault("intent_propagation", {})
            parsed.setdefault("dag_structure", {
                "execution_order": [],
                "parallel_groups": []
            })
            parsed.setdefault("resolution_notes", "No resolution notes provided.")
            return parsed
        except json.JSONDecodeError:
            return self._get_fallback_output()
        
    async def _generate_with_cot_self_consistency(
        self,
        main_node: str,
        main_intent: str,
        graph_desc: str,
        num_samples: int = 3,  # è‡ªæˆ‘ä¸€è‡´æ€§é‡‡æ ·æ•°
        max_retries: int = 2   # éªŒè¯å¤±è´¥åæœ€å¤§é‡è¯•æ¬¡æ•°
    ) -> Dict:
        """
        ä½¿ç”¨æ€ç»´é“¾ + è‡ªæˆ‘ä¸€è‡´æ€§ + éªŒè¯åé¦ˆ ç”Ÿæˆæœ€ç»ˆç­–ç•¥
        """

        # Step 0: æ„å»ºåˆ†æ­¥æ€ç»´é“¾æç¤ºæ¨¡æ¿ï¼ˆCoTï¼‰
        cot_prompt = PromptTemplate.from_template(
            """ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„ç³»ç»Ÿæ¶æ„å¸ˆã€‚è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤é€æ­¥æ¨ç†ï¼š

ã€STEP 1: è¯†åˆ«å¾ªç¯ä¾èµ–ã€‘
è¯·åˆ—å‡ºå›¾ä¸­å­˜åœ¨çš„æ‰€æœ‰å¾ªç¯ä¾èµ–è·¯å¾„ï¼ˆå¦‚ Aâ†’Bâ†’Aï¼‰ï¼Œå¹¶è¯´æ˜æ¯æ¡ç¯çš„ä¸šåŠ¡å«ä¹‰ã€‚
å½“å‰å›¾ï¼š
{graph_desc}

ã€STEP 2: è§£ç¯ç­–ç•¥è®¾è®¡ã€‘
é’ˆå¯¹æ¯ä¸ªç¯ï¼Œæå‡ºå…·ä½“çš„è§£ç¯æ–¹æ¡ˆï¼ˆå¦‚ï¼šè¾¹åè½¬ã€å¼•å…¥ä¸­é—´çŠ¶æ€ã€æ‹†åˆ†é˜¶æ®µã€å¼‚æ­¥åŒ–ã€æ·»åŠ ç¼“å†²ç­‰ï¼‰ã€‚
è¯·è¯´æ˜é€‰æ‹©è¯¥æ–¹æ¡ˆçš„ä¸šåŠ¡åˆç†æ€§ã€‚

ã€STEP 3: æ„å›¾ä¼ æ’­æ¨å¯¼ã€‘
åŸºäºä¸»èŠ‚ç‚¹ '{main_node}' çš„ä¸»æ„å›¾ï¼š'{main_intent}'ï¼Œä¸ºæ¯ä¸ªèŠ‚ç‚¹æ¨å¯¼â€œä¿®æ”¹æ„å›¾â€ã€‚
- ä¸»èŠ‚ç‚¹æ˜¯å¦éœ€è¦è¿½åŠ é™„åŠ æ„å›¾ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ
- å…¶ä»–èŠ‚ç‚¹çš„æ´¾ç”Ÿæ„å›¾æ˜¯ä»€ä¹ˆï¼Ÿå¦‚ä½•æ”¯æŒä¸»ç›®æ ‡ï¼Ÿ

ã€STEP 4: æ„å»ºæ‰§è¡ŒDAGã€‘
åŸºäºè§£ç¯åçš„ç»“æ„ï¼Œè¾“å‡ºï¼š
- execution_order: æ‹“æ‰‘åºï¼ˆå¿…é¡»æ— ç¯ï¼‰
- parallel_groups: å¯å¹¶è¡Œæ‰§è¡Œç»„
è¯·ç¡®ä¿ execution_order ä¸­çš„é¡ºåºèƒ½æ”¯æŒæ‰€æœ‰ä¾èµ–ã€‚

ã€STEP 5: è‡ªæˆ‘æ£€æŸ¥ã€‘
æ£€æŸ¥ä½ çš„æ–¹æ¡ˆï¼š
- æ˜¯å¦æ‰€æœ‰ç¯éƒ½å·²è§£å¼€ï¼Ÿ
- execution_order æ˜¯å¦åˆæ³•æ‹“æ‰‘åºï¼Ÿ
- æ„å›¾æ˜¯å¦è¦†ç›–æ‰€æœ‰èŠ‚ç‚¹ï¼Ÿ
- æ˜¯å¦æœ‰é—æ¼æˆ–çŸ›ç›¾ï¼Ÿ

æœ€åï¼Œè¾“å‡ºä¸¥æ ¼ JSON æ ¼å¼ï¼š
{{
  "intent_propagation": {{...}},
  "dag_structure": {{...}},
  "resolution_notes": "..."
}}
"""
        )

        chain = cot_prompt | self.llm | StrOutputParser()

        for retry in range(max_retries + 1):
            print(f"ğŸ” ç¬¬ {retry + 1} è½®æ¨ç†ï¼ˆå« {num_samples} ä¸ªå¹¶è¡Œæ ·æœ¬ï¼‰...")

            # å¹¶è¡Œç”Ÿæˆå¤šä¸ªæ¨ç†è·¯å¾„ï¼ˆSelf-Consistencyï¼‰
            tasks = [
                chain.ainvoke({
                    "main_node": main_node,
                    "main_intent": main_intent,
                    "graph_desc": graph_desc
                })
                for _ in range(num_samples)
            ]
            raw_outputs = await asyncio.gather(*tasks, return_exceptions=True)

            # è§£æ & éªŒè¯æ¯ä¸ªæ ·æœ¬
            candidates = []
            for i, output in enumerate(raw_outputs):
                if isinstance(output, Exception):
                    print(f"âš ï¸  æ ·æœ¬ {i+1} æ‰§è¡Œå‡ºé”™: {str(output)}")
                    continue

                parsed = self._parse_json_output(output)
                is_valid, error_msg = self._validate_strategy(parsed)
                if is_valid:
                    candidates.append(parsed)
                    print(f"âœ… æ ·æœ¬ {i+1} éªŒè¯é€šè¿‡")
                else:
                    print(f"âŒ æ ·æœ¬ {i+1} éªŒè¯å¤±è´¥: {error_msg}")

            if not candidates:
                if retry < max_retries:
                    # æ‰€æœ‰æ ·æœ¬éƒ½å¤±è´¥ â†’ ç”Ÿæˆåé¦ˆï¼Œå¼•å¯¼ä¸‹ä¸€è½®
                    feedback = "æ‰€æœ‰å€™é€‰æ–¹æ¡ˆå‡æœªé€šè¿‡éªŒè¯ã€‚å¸¸è§é”™è¯¯ï¼š" + "; ".join(
                        set(str(e) for e in raw_outputs if isinstance(e, Exception)) |
                        set("ç»“æ„éæ³•" for _ in range(len(raw_outputs) - len(candidates)))
                    )
                    graph_desc = self._enhance_graph_desc_with_feedback(graph_desc, feedback)
                    print(f"ğŸ”„ è¿›å…¥ä¸‹ä¸€è½®é‡è¯•ï¼Œå·²æ³¨å…¥åé¦ˆ: {feedback[:100]}...")
                    await asyncio.sleep(1)  # é¿å… QPM è¶…é™
                else:
                    print("ğŸ”¥ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè¿”å›é™çº§æ–¹æ¡ˆ")
                    return self._get_fallback_output()
            else:
                # Self-Consistency: å¯¹å…³é”®å­—æ®µæŠ•ç¥¨å–å…±è¯†
                consensus_strategy = self._extract_consensus(candidates)
                print(f"ğŸ¯ {len(candidates)} ä¸ªæœ‰æ•ˆæ ·æœ¬ï¼Œå·²ç”Ÿæˆå…±è¯†æ–¹æ¡ˆ")
                return consensus_strategy

        return self._get_fallback_output()  # ç†è®ºä¸Šä¸ä¼šæ‰§è¡Œåˆ°è¿™é‡Œ

    def _validate_strategy(self, strategy: Dict) -> Tuple[bool, str]:
        """éªŒè¯ç”Ÿæˆçš„ç­–ç•¥æ˜¯å¦åˆæ³•ï¼ˆæ ¸å¿ƒï¼šexecution_order å¿…é¡»æ˜¯åˆæ³•æ‹“æ‰‘åºï¼‰"""
        try:
            order = strategy.get("dag_structure", {}).get("execution_order", [])
            if not order:
                return False, "execution_order ä¸ºç©º"

            # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤èŠ‚ç‚¹
            if len(order) != len(set(order)):
                return False, "execution_order åŒ…å«é‡å¤èŠ‚ç‚¹"

            # æ„å»ºæœ‰å‘å›¾æ£€æŸ¥æ˜¯å¦æœ‰ç¯ï¼ˆåŸºäºé¡ºåºéšå«çš„ä¾èµ–ï¼‰
            # æ³¨æ„ï¼šæˆ‘ä»¬ä¸é‡å»ºåŸå§‹å›¾ï¼Œè€Œæ˜¯æ£€æŸ¥è¾“å‡ºé¡ºåºæ˜¯å¦è‡ªæ´½ï¼ˆæ— ç¯ï¼‰
            G_test = nx.DiGraph()
            G_test.add_nodes_from(order)
            # å‡è®¾é¡ºåºä¸­é å‰çš„èŠ‚ç‚¹åº”ä¾èµ–é åçš„ï¼Ÿä¸ï¼Œæˆ‘ä»¬æ£€æŸ¥é¡ºåºæœ¬èº«æ˜¯å¦å½¢æˆç¯ï¼ˆä¸å¯èƒ½ï¼Œå› ä¸ºæ˜¯åˆ—è¡¨ï¼‰
            # æ›´åˆç†çš„éªŒè¯ï¼šæ£€æŸ¥ parallel_groups æ˜¯å¦ä¸ execution_order ä¸€è‡´
            groups = strategy.get("dag_structure", {}).get("parallel_groups", [])
            flat_groups = [item for group in groups for item in group]
            if set(flat_groups) != set(order):
                return False, "parallel_groups ä¸ execution_order èŠ‚ç‚¹ä¸ä¸€è‡´"

            # æœ€å¼ºéªŒè¯ï¼šæ¨¡æ‹Ÿè°ƒåº¦ï¼Œæ£€æŸ¥ç»„å†…æ— ä¾èµ–ï¼ˆç†æƒ³æƒ…å†µéœ€è¦åŸå§‹ä¾èµ–å›¾ï¼Œè¿™é‡Œç®€åŒ–ï¼‰
            # ç”±äºæˆ‘ä»¬æ²¡æœ‰åŸå§‹ä¾èµ–è¾¹ç”¨äºéªŒè¯ï¼Œæ­¤å¤„ä»…åšåŸºç¡€ç»“æ„æ£€æŸ¥
            # æœªæ¥å¯ä¼ å…¥åŸå§‹å›¾ç”¨äºæ›´ä¸¥æ ¼éªŒè¯

            return True, "OK"
        except Exception as e:
            return False, f"éªŒè¯å¼‚å¸¸: {str(e)}"

    def _enhance_graph_desc_with_feedback(self, graph_desc: str, feedback: str) -> str:
        """åœ¨å›¾æè¿°åè¿½åŠ å¤±è´¥åé¦ˆï¼Œå¼•å¯¼LLMä¿®æ­£"""
        return f"""{graph_desc}

âš ï¸ã€é‡è¦åé¦ˆã€‘
ä¸Šä¸€è½®ç”Ÿæˆçš„æ–¹æ¡ˆå­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼Œè¯·åŠ¡å¿…ä¿®æ­£ï¼š
{feedback}

è¯·é‡æ–°æ€è€ƒè§£ç¯ç­–ç•¥å’Œæ‰§è¡Œé¡ºåºï¼Œç¡®ä¿è¾“å‡ºçš„ execution_order æ˜¯ä¸¥æ ¼æ— ç¯çš„æ‹“æ‰‘åºåˆ—ã€‚
"""

    def _extract_consensus(self, candidates: List[Dict]) -> Dict:
        """ä»å¤šä¸ªå€™é€‰æ–¹æ¡ˆä¸­æå–å…±è¯†ï¼ˆç®€å•æŠ•ç¥¨æœºåˆ¶ï¼‰"""
        if len(candidates) == 1:
            return candidates[0]

        # å¯¹ execution_order è¿›è¡ŒæŠ•ç¥¨ï¼ˆæœ€æ ¸å¿ƒå­—æ®µï¼‰
        all_orders = [tuple(cand["dag_structure"]["execution_order"]) for cand in candidates if "dag_structure" in cand]
        if all_orders:
            order_counter = Counter(all_orders)
            consensus_order = order_counter.most_common(1)[0][0]
        else:
            consensus_order = candidates[0]["dag_structure"]["execution_order"]

        # å¯¹ parallel_groups æŠ•ç¥¨ï¼ˆè½¬ä¸º frozenset(tuple) ä»¥ä¾¿å“ˆå¸Œï¼‰
        all_groups = []
        for cand in candidates:
            groups = cand.get("dag_structure", {}).get("parallel_groups", [])
            # æ ‡å‡†åŒ–ï¼šç»„å†…æ’åº + ç»„é—´æ’åº
            normalized = tuple(sorted(tuple(sorted(group)) for group in groups))
            all_groups.append(normalized)
        
        if all_groups:
            group_counter = Counter(all_groups)
            consensus_groups_tuple = group_counter.most_common(1)[0][0]
            consensus_groups = [list(group) for group in consensus_groups_tuple]
        else:
            consensus_groups = candidates[0]["dag_structure"]["parallel_groups"]

        # intent_propagation: åˆå¹¶æ‰€æœ‰èŠ‚ç‚¹çš„æ„å›¾ï¼ˆå–ç¬¬ä¸€ä¸ªéç©ºï¼Œæˆ–æ‹¼æ¥ï¼‰
        consensus_intents = {}
        node_intent_votes = defaultdict(list)
        
        for cand in candidates:
            intents = cand.get("intent_propagation", {})
            for node, intent_data in intents.items():
                node_intent_votes[node].append(intent_data)
        
        for node, votes in node_intent_votes.items():
            # å–ç¬¬ä¸€ä¸ªï¼Œæˆ–åˆå¹¶ derived_intent
            first = votes[0]
            if "derived_intent" in first:
                # åˆå¹¶ä¸åŒç‰ˆæœ¬çš„æ´¾ç”Ÿæ„å›¾ï¼ˆå»é‡ï¼‰
                all_derived = list(set(v.get("derived_intent", "") for v in votes if v.get("derived_intent")))
                consensus_intents[node] = {
                    "derived_intent": " | ".join(all_derived) if len(all_derived) > 1 else all_derived[0]
                }
            elif "primary_intent" in first:
                # ä¸»èŠ‚ç‚¹ï¼šåˆå¹¶é™„åŠ æ„å›¾
                primary = first.get("primary_intent", "")
                all_additional = list(set(
                    a for v in votes for a in v.get("additional_intents", [])
                ))
                consensus_intents[node] = {
                    "primary_intent": primary,
                    "additional_intents": all_additional
                }

        # resolution_notes: å–æœ€é•¿çš„æˆ–æ‹¼æ¥
        all_notes = [cand.get("resolution_notes", "") for cand in candidates]
        consensus_notes = " | ".join(set(all_notes)) if len(set(all_notes)) > 1 else all_notes[0]

        return {
            "intent_propagation": consensus_intents,
            "dag_structure": {
                "execution_order": list(consensus_order),
                "parallel_groups": consensus_groups
            },
            "resolution_notes": consensus_notes
        }


    def _get_fallback_output(self) -> Dict:
        return {
            "intent_propagation": {},
            "dag_structure": {
                "execution_order": [],
                "parallel_groups": []
            },
            "resolution_notes": "LLM è¾“å‡ºè§£æå¤±è´¥ï¼Œéœ€äººå·¥ä»‹å…¥ã€‚"
        }
    

    def _format_graph_for_llm(self, graph: nx.DiGraph, main_node: str) -> str:
        """æ ¼å¼åŒ–å›¾ç»“æ„ï¼Œçªå‡ºä¸»èŠ‚ç‚¹å’Œæƒé‡"""
        lines = [f"ä¸»å˜æ›´èŠ‚ç‚¹: {main_node}"]
        lines.append("\nå—å½±å“èŠ‚ç‚¹ï¼ˆæŒ‰å½±å“æƒé‡æ’åºï¼‰:")
        sorted_nodes = sorted(graph.nodes, key=lambda n: graph.nodes[n].get("impact_strength", 0), reverse=True)
        for node in sorted_nodes:
            impact = graph.nodes[node].get("impact_strength", 0.0)
            mark = " <<< ä¸»èŠ‚ç‚¹" if node == main_node else ""
            lines.append(f"- {node} (æƒé‡: {impact:.2f}){mark}")

        lines.append("\nä¾èµ–å…³ç³»ï¼ˆå¯èƒ½å­˜åœ¨å¾ªç¯ï¼‰:")
        for u, v in graph.edges:
            edge_type = graph.edges[u, v].get("type", "affects")
            lines.append(f"  {u} --[{edge_type}]--> {v}")
        return "\n".join(lines)
    async def run(self, change_request: Dict) -> Dict:
        graph = change_request["graph"]
        main_node = change_request["main_node"]
        main_intent = change_request["main_intent"]
        # graph_hash = self._graph_to_hash(graph, main_node, main_intent)

        # ç¼“å­˜æ£€æŸ¥ï¼ˆä¸å˜ï¼‰
        # cached = self._retrieve_similar_case(graph_hash)
        # if cached:
        #     return {
        #         "change_id": str(uuid.uuid4()),
        #         "strategy": cached.coordination_strategy,
        #         "source": "cache",
        #         "graph_hash": graph_hash
        #     }

        # ğŸ†• è°ƒç”¨æ–°æ¨ç†å¼•æ“
        print(f"ğŸ§ ã€CoT + Self-Consistencyã€‘åŸºäºä¸»æ„å›¾ '{main_intent}' ç”Ÿæˆåè°ƒæ–¹æ¡ˆ...")
        graph_desc = self._format_graph_for_llm(graph, main_node)
        
        # ğŸš€ æ ¸å¿ƒæ›¿æ¢ï¼šä½¿ç”¨æ–°æ–¹æ³•
        strategy = await self._generate_with_cot_self_consistency(
            main_node=main_node,
            main_intent=main_intent,
            graph_desc=graph_desc,
            num_samples=3,      # å¯é…ç½®
            max_retries=2       # å¯é…ç½®
        )

        # # ç¼“å­˜ï¼ˆä¸å˜ï¼‰
        # vector = self._get_or_create_vector(graph)
        # idx = len(self.vectors)
        # self.vector_index.add(vector.reshape(1, -1))
        # self.vectors.append(vector)
        # self.hash_to_idx[graph_hash] = idx

        # self.pattern_kb[graph_hash] = ChangePattern(
        #     graph_hash=graph_hash,
        #     coordination_strategy=strategy,
        #     metadata={
        #         "main_node": main_node,
        #         "main_intent": main_intent,
        #     }
        # )

        return {
            "change_id": str(uuid.uuid4()),
            "strategy": strategy,
            "source": "llm_reasoning_cot_sc",  # æ›´æ–°æ¥æºæ ‡è®°
            # "graph_hash": graph_hash
        }