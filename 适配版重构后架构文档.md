# Flora 多智能体协作系统 - 适配版重构后架构文档

## 1. 架构概述

本文档基于 Flora 系统现有代码结构，详细描述如何适配到重构后的六层次架构设计。文档包含现有代码到重构后架构的具体映射关系、文件迁移路径和实现调整方案，确保系统平滑过渡到新架构。

## 2. 现有代码到重构后架构的映射关系

### 2.1 总体映射概览

| 现有目录/文件 | 重构后目录/文件 | 变更类型 |
|--------------|----------------|----------|
| agent/agent_registry.py | agents/tree/node_service.py 和 agents/tree/relationship_service.py | 拆分与重构 |
| agent/agent_actor.py | agents/agent_actor.py | 重构（集成并行执行管理器） |
| agent/coordination/task_coordinator.py | agents/coordination/task_router.py<br>agents/coordination/task_planner.py<br>agents/coordination/context_resolver.py | 拆分为三个组件 |
| agent/concurrent/concurrent_actor.py | agents/parallel/orchestrator.py | 重构（解决VideoWorker问题） |
| agent/concurrent/llm_demension_parser.py | agents/parallel/dimension_parser.py | 迁移与重命名 |
| agent/memory/memory_actor.py | capability_actors/memory_actor.py | 迁移到能力actor层 |
| agent/io/data_actor.py | capability_actors/data_actor.py | 迁移到能力actor层 |
| agent/mcp/mcp_actor.py | capability_actors/mcp_actor.py | 迁移到能力actor层 |
| agent/excute/dify_actor.py | capability_actors/dify_actor.py | 迁移到能力actor层 |
| agent/io/ | external/database/ 和 agents/data/ | 拆分与重构 |
| action_implementations/dify_connector.py | external/dify/connector.py | 迁移与重构 |
| Observer/observer_actor.py | events/event_actor.py | 重命名与重构 |
| Observer/task_event.py | events/task_event.py | 迁移与扩展 |
| agent/message.py | common/messages/ | 迁移与拆分 |
| llm_memory_system/ | capabilities/llm_memory/ (核心逻辑) | 迁移为底层能力 |
| multifeature/ | capabilities/multifeature/ (核心逻辑) | 迁移为底层能力 |

## 3. 各层次详细迁移与实现指南

### 3.1 入口层（entry_layer/）

**功能**：系统外部访问入口，负责接收用户请求并转发到对应租户的根 actor

**文件结构**：
```
entry_layer/
├── __init__.py
├── api_server.py       # 新建：API服务器实现
├── request_handler.py  # 新建：请求处理器
├── tenant_router.py    # 新建：租户路由分发器
└── auth_middleware.py  # 新建：认证中间件
```

**迁移说明**：
- 此层为全新创建，负责封装现有系统的入口点逻辑
- 从 main.py 提取相关请求处理代码到 api_server.py
- tenant_router.py 将基于现有的 AgentRegistry 功能实现租户路由

### 3.2 外部对接层（external/）

**功能**：底层能力层与外部系统的对接层，负责连接持久化、外部数据库、外部API、dify等

**文件结构**：
```
external/
├── __init__.py
├── adapter_base.py     # 新建：适配器基类
├── agent_structure/    # 新建：agent_actor树形结构管理
│   ├── __init__.py
│   ├── structure_interface.py # 新建：树形结构管理抽象接口
│   ├── neo4j_structure.py     # 基于AgentRegistry中Neo4j相关代码
│   └── structure_factory.py   # 新建：工厂类，支持未来切换其他实现
├── business_data/      # 新建：业务数据管理（供vanna读取的业务数据库）
│   ├── __init__.py
│   ├── data_interface.py      # 新建：业务数据抽象接口
│   ├── mysql_business.py      # 基于mysql_pool.py实现
├── internal_storage/   # 新建：内部持久化存储
│   ├── __init__.py
│   ├── storage_interface.py   # 新建：内部存储抽象接口
│   ├── sqlite_storage.py      # 基于optimization/sqlite_task_persistence.py
│   └── storage_factory.py     # 新建：工厂类，支持未来切换其他实现
└── execution_connectors/     # 执行连接接口及实现
    ├── __init__.py
    ├── base_connector.py     # 新建：执行连接抽象接口
    ├── connector_factory.py  # 新建：工厂类，支持多种执行方式
    └── dify/                 # dify执行方式实现
        ├── __init__.py
        ├── connector.py      # 迁移并重构dify_connector.py
        └── schema_parser.py
```

**系统组件职责与结构分离**：
1. **agent_structure/**：专门管理agent_actor的树形结构
   - 基于Neo4j实现，但提供抽象接口
   - 负责Agent之间的层次关系、引用管理和树形导航
   - 支持未来扩展到其他图数据库实现

2. **execution_connectors/**：执行连接接口及实现
   - 提供统一的执行连接抽象接口
   - 通过工厂模式支持多种执行方式
   - 已实现dify执行方式，未来可轻松扩展其他执行引擎

3. **business_data/**：负责业务数据管理
   - 与Vanna系统紧密集成
   - 目前基于MySQL实现，但通过抽象接口支持未来扩展到其他数据库
   - 处理用户查询和业务逻辑相关的数据操作

4. **internal_storage/**：处理内部持久化需求
   - 目前基于SQLite实现，通过抽象接口支持未来扩展
   - 负责优化循环状态、自学习模型、记忆数据等内部状态的持久化
   - 提供工厂类简化实现切换

**迁移示例**：
```python
# 1. Agent树形结构管理模块 - external/agent_structure/

# external/agent_structure/structure_interface.py
from abc import ABC, abstractmethod

class AgentStructureInterface(ABC):
    @abstractmethod
    def get_agent_relationship(self, agent_id):
        """获取Agent的父子关系"""
        pass
    
    @abstractmethod
    def load_all_agents(self):
        """加载所有Agent节点"""
        pass
    
    @abstractmethod
    def close(self):
        """关闭连接"""
        pass

# external/agent_structure/neo4j_structure.py - 基于AgentRegistry中的Neo4j代码
from neo4j import GraphDatabase
from .structure_interface import AgentStructureInterface

class Neo4JAgentStructure(AgentStructureInterface):
    def __init__(self, uri, user, password):
        # 从AgentRegistry迁移Neo4j连接逻辑
        self.driver = GraphDatabase.driver(uri, auth=(user, password))
    
    def get_agent_relationship(self, agent_id):
        # 从AgentRegistry迁移树形结构查询逻辑
        with self.driver.session() as session:
            result = session.read_transaction(self._get_relationship_tx, agent_id)
            return result
    
    def _get_relationship_tx(self, tx, agent_id):
        # 从AgentRegistry._load_all_agents_tx迁移查询逻辑
        pass
    
    def load_all_agents(self):
        # 从AgentRegistry._load_all_agents迁移
        pass
    
    def close(self):
        self.driver.close()

# external/agent_structure/structure_factory.py
from .neo4j_structure import Neo4JAgentStructure

def create_agent_structure(config):
    """工厂方法创建Agent结构管理器"""
    structure_type = config.get('type', 'neo4j')
    if structure_type == 'neo4j':
        return Neo4JAgentStructure(
            uri=config['uri'],
            user=config['user'],
            password=config['password']
        )
    # 未来可以添加其他实现
    raise ValueError(f"Unsupported agent structure type: {structure_type}")

# 2. 业务数据管理模块 - external/business_data/

# external/business_data/data_interface.py
from abc import ABC, abstractmethod

class BusinessDataInterface(ABC):
    @abstractmethod
    def execute_query(self, query, params=None):
        """执行业务数据查询"""
        pass
    
    @abstractmethod
    def close(self):
        """关闭连接"""
        pass

# external/business_data/mysql_business.py - 基于mysql_pool.py
from .data_interface import BusinessDataInterface

class MySQLBusinessData(BusinessDataInterface):
    def __init__(self, config):
        # 从mysql_pool.py迁移连接池实现
        self.pool = self._create_pool(config)
    
    def _create_pool(self, config):
        # 从mysql_pool.py迁移连接池创建逻辑
        pass
    
    def execute_query(self, query, params=None):
        # 从现有数据查询逻辑迁移
        pass
    
    def close(self):
        # 关闭连接池
        pass

# 3. 内部持久化存储模块 - external/internal_storage/

# external/internal_storage/storage_interface.py
from abc import ABC, abstractmethod

class InternalStorageInterface(ABC):
    @abstractmethod
    def save_task_state(self, task_id, state_data):
        """保存任务状态"""
        pass
    
    @abstractmethod
    def load_task_state(self, task_id):
        """加载任务状态"""
        pass
    
    @abstractmethod
    def save_learning_model(self, model_id, model_data):
        """保存自学习模型"""
        pass
    
    @abstractmethod
    def close(self):
        """关闭连接"""
        pass

# external/internal_storage/sqlite_storage.py - 基于sqlite_task_persistence.py
import sqlite3
from .storage_interface import InternalStorageInterface

class SQLiteInternalStorage(InternalStorageInterface):
    def __init__(self, db_path):
        # 从sqlite_task_persistence.py迁移初始化逻辑
        self.conn = sqlite3.connect(db_path)
        self._init_tables()
    
    def _init_tables(self):
        # 从sqlite_task_persistence.py迁移表初始化逻辑
        pass
    
    def save_task_state(self, task_id, state_data):
        # 从sqlite_task_persistence.py迁移持久化逻辑
        pass
    
    def load_task_state(self, task_id):
        # 加载任务状态
        pass
    
    def save_learning_model(self, model_id, model_data):
        # 保存自学习模型
        pass
    
    def close(self):
        self.conn.close()

# external/internal_storage/storage_factory.py
from .sqlite_storage import SQLiteInternalStorage

def create_internal_storage(config):
    """工厂方法创建内部存储管理器"""
    storage_type = config.get('type', 'sqlite')
    if storage_type == 'sqlite':
        return SQLiteInternalStorage(db_path=config['db_path'])
    # 未来可以添加其他实现（如PostgreSQL等）
    raise ValueError(f"Unsupported internal storage type: {storage_type}")
```

### 3.3 底层能力层（capabilities/）

**功能**：提供各种基础能力，位于外部连接层之上

**文件结构**：
```
capabilities/
├── __init__.py
├── capability_base.py  # 新建：能力基类
├── registry.py         # 新建：能力注册表
├── llm_memory/        # 基于llm_memory_system/
│   ├── __init__.py
│   ├── manager.py      # 从llm_memory_system/manager.py迁移
│   ├── short_term.py   # 从llm_memory_system/short_term.py迁移
│   └── resource_memory.py # 从llm_memory_system/resourcememory.py迁移
├── loop_queue/        # 循环队列实现，与thespian兼容
│   ├── __init__.py
│   ├── queue_interface.py  # 新建：循环队列抽象接口
│   ├── thespian_queue.py   # 基于agent/optimization的循环逻辑，与thespian兼容
│   └── queue_factory.py    # 新建：工厂类，支持未来切换不同队列实现
├── optimization/      # 自优化方法框架
│   ├── __init__.py
│   ├── optimization_interface.py # 新建：优化方法抽象接口，定义通用自优化接口
│   └── optuna_optimizer.py      # 新建：基于Optuna的并行执行优化器，提供多维度参数优化能力
├── multifeature/      # 自优化方法的一种实现（基于多特征）
│   ├── __init__.py
│   ├── inference.py    # 从multifeature/inference.py迁移
│   └── self_learning.py    # 迁移自学习核心逻辑
├── llm/               # 基于llm/qwen.py
│   ├── __init__.py
│   └── qwen_adapter.py
├── decision/          # 基于change_orchestrator/
│   ├── __init__.py
│   └── engine_adapter.py
├── routing/           # 业务路由与调度能力
│   ├── __init__.py
│   ├── task_router.py      # 从TaskCoordinator._select_best_actor迁移
│   ├── task_planner.py     # 从TaskCoordinator.plan_subtasks迁移
│   └── context_resolver.py # 从TaskCoordinator.resolve_context迁移，依赖vanna提供数据补全能力，优先使用智能体记忆填充数据，再请求外部数据
└── data_analytics/    # 数据补全与分析能力
    ├── __init__.py
    ├── data_interface.py   # 新建：数据访问抽象接口
    ├── data_actor.py       # 基于data_interface实现的数据访问
    ├── query_processor.py  # 从data_query_actor.py迁移，实现查询处理逻辑
    ├── utils.py            # 从io/utils.py迁移
    └── vanna/              # 基于io/vanna_qwen_chroma.py，为context_resolver提供数据补全能力
        ├── __init__.py
        ├── vanna_base.py   # 新建：Vanna抽象基类
        ├── qwen_integration.py # 基于vanna_qwen_chroma.py
        └── model_factory.py   # 新建：模型工厂
```

**组件说明**：
1. **loop_queue/**：循环队列实现，与thespian兼容
   - 提供统一的循环队列抽象接口，支持循环任务的管理和执行
   - thespian_queue.py实现了与thespian框架兼容的循环逻辑
   - 通过工厂模式支持未来切换不同的队列实现
   - 负责循环任务的调度、状态管理和持久化

2. **optimization/**：自优化方法框架
   - 提供通用的优化方法抽象接口，定义自优化的标准行为规范
   - 作为所有优化方法实现的基础，确保接口一致性
   - 支持未来添加多种不同的优化算法和策略
   - 为上层组件提供统一的优化能力调用方式
   
3. **optuna_optimizer.py**：基于Optuna的并行执行优化器
   - 提供多维度参数空间自动探索和优化能力
   - 支持批量并行执行不同参数组合的任务
   - 通过LLM实现向量到指令的转换和结果评分
   - 提供优化过程的监控和最佳参数记录
   - 与ActorSystem集成，支持分布式并行执行

3. **multifeature/**：自优化方法的一种实现（基于多特征）
   - 基于optimization_interface实现的多特征自优化实现
   - 迁移现有的自学习核心逻辑，支持系统的优化和改进
   - inference.py提供推理能力，支持自学习过程中的逻辑推理
   - 可以被循环队列组件利用进行任务优化

4. **routing/**：业务路由与调度能力
   - 提供任务路由抽象，根据任务特性选择最合适的执行器
   - 实现任务计划调度，支持子任务的规划和分解
   - 提供上下文解析能力，解决任务执行中的上下文依赖
   - context_resolver优先使用智能体记忆填充数据，再请求外部数据，提高响应效率
   - 基于change_orchestrator/decision_engine.py提供决策支持
   - 采用插件化设计，支持未来替换为更优化的路由算法

5. **data_analytics/**：数据补全与分析能力
   - 提供统一的数据访问抽象接口（data_interface.py），定义标准数据操作方法
   - 实现基于接口的数据访问组件（data_actor.py），支持多种数据源的统一访问
   - 实现数据查询处理，支持复杂查询的解析和执行
   - 集成vanna模块提供智能数据补全能力，为context_resolver提供支持
   - 采用接口抽象与实现分离的设计，支持未来替换不同的数据访问实现

**optuna_optimizer.py实现示例代码**：
```python
# capabilities/optimization/optuna_optimizer.py
import optuna
from typing import List, Dict, Any, Tuple, Optional
from abc import ABC, abstractmethod

class OptunaOptimizer:
    """基于Optuna的并行执行优化器"""
    
    def __init__(self, direction: str = "maximize", max_concurrent: int = 4):
        """
        初始化Optuna优化器
        
        Args:
            direction: 优化方向，"maximize"或"minimize"
            max_concurrent: 最大并发执行任务数
        """
        self.study = optuna.create_study(direction=direction)
        self.max_concurrent = max_concurrent
        self.vector_dim = 0
        
    def initialize_optimization_space(self, vector_dim: int):
        """
        初始化优化空间维度
        
        Args:
            vector_dim: 优化向量维度
        """
        self.vector_dim = vector_dim
    
    def suggest_parameters(self, batch_size: int) -> List[Tuple[optuna.Trial, List[float]]]:
        """
        批量建议参数组合
        
        Args:
            batch_size: 批量大小
            
        Returns:
            包含trial对象和参数向量的列表
        """
        trials = []
        for _ in range(min(batch_size, self.max_concurrent)):
            trial = self.study.ask()
            # 在[-1,1]^D空间采样参数
            vector = [trial.suggest_float(f"x{i}", -1.0, 1.0) for i in range(self.vector_dim)]
            trials.append((trial, vector))
        return trials
    
    def update_optimization_results(self, trials_results: List[Tuple[optuna.Trial, float]]):
        """
        更新优化结果
        
        Args:
            trials_results: trial对象和对应评分的列表
        """
        for trial, score in trials_results:
            self.study.tell(trial, score)
    
    def get_best_parameters(self) -> Dict[str, Any]:
        """
        获取最佳参数
        
        Returns:
            最佳参数字典
        """
        if self.study.best_params:
            # 将Optuna参数格式转换为向量格式
            vector = [self.study.best_params[f"x{i}"] for i in range(self.vector_dim)]
            return {
                "vector": vector,
                "value": self.study.best_value,
                "params": self.study.best_params
            }
        return None

# 与LLM集成的优化协调器
class OptimizationOrchestrator:
    """优化协调器，负责LLM与优化器的集成"""
    
    def __init__(self, llm_orchestrator, optimizer: OptunaOptimizer):
        """
        初始化优化协调器
        
        Args:
            llm_orchestrator: LLM编排器，负责维度发现和向量转换
            optimizer: Optuna优化器实例
        """
        self.llm_orchestrator = llm_orchestrator
        self.optimizer = optimizer
        
    async def discover_optimization_dimensions(self) -> Dict[str, Any]:
        """
        自动发现优化维度
        
        Returns:
            包含维度信息的字典
        """
        schema = await self.llm_orchestrator.discover_schema()
        # 初始化优化空间
        self.optimizer.initialize_optimization_space(len(schema['dimensions']))
        return schema
    
    async def vector_to_instruction(self, vector: List[float]) -> str:
        """
        将参数向量转换为执行指令
        
        Args:
            vector: 参数向量
            
        Returns:
            执行指令字符串
        """
        return await self.llm_orchestrator.vector_to_instruction(vector)
    
    async def evaluate_output(self, output: str) -> Dict[str, Any]:
        """
        评估执行输出并返回评分
        
        Args:
            output: 执行输出内容
            
        Returns:
            包含评分和反馈的字典
        """
        return await self.llm_orchestrator.output_to_score(output)

# 并行执行管理器接口
class ExecutionManagerInterface(ABC):
    """执行管理器抽象接口"""
    
    @abstractmethod
    async def run_batch(self, instructions: List[str], trial_numbers: List[int]) -> Dict[str, Any]:
        """
        批量执行指令
        
        Args:
            instructions: 指令列表
            trial_numbers: 试验编号列表
            
        Returns:
            包含执行结果的字典
        """
        pass
```

**context_resolver数据填充示例代码**：
```python
# routing/context_resolver.py
from typing import Dict, Any, List
from data_analytics.vanna.qwen_integration import QwenVannaIntegration
from memory.memory_actor import MemoryActor

class ContextResolver:
    """上下文解析器，优先使用智能体记忆填充数据，再通过分层搜索找到数据节点，最后使用vanna从该节点查询实际数据"""
    
    def __init__(self, agent_id: str, registry):
        self.agent_id = agent_id
        self.registry = registry
        self.memory_actor = MemoryActor(agent_id)
        self.vanna_integration = QwenVannaIntegration()
    
    def resolve_context(self, ctx: Dict[str, str], agent_id) -> Dict[str, Any]:
        """解析上下文数据，实现正确的数据获取流程：记忆优先 → 节点查找 → vanna查询"""
        result = {}
        current_agent_id = agent_id or self.agent_id
        
        for key, value_desc in ctx.items():
            # 1. 第一步：优先从智能体记忆中获取数据
            memory_data = self._fetch_from_memory(key)
            if memory_data is not None:
                result[key] = memory_data
                continue
            
            # 2. 第二步：使用分层搜索查找数据所在的节点
            query = f"变量名: '{key}', 值描述: '{value_desc}'"
            node_code = self._resolve_kv_via_layered_search(current_agent_id, query, key)
            
            if node_code:
                # 3. 第三步：通过vanna从找到的节点查询实际数据
                data_value = self._fetch_data_using_vanna(node_code, key, value_desc)
                if data_value is not None:
                    result[key] = data_value
                    # 4. 将获取到的数据存储到记忆中供未来使用
                    self.memory_actor.store_memory_item(key, data_value)
                else:
                    result[key] = None
            else:
                # 5. 如果找不到对应的节点，尝试使用vanna进行通用查询作为最后的后备方案
                fallback_value = self._vanna_general_query(ctx, key, value_desc)
                result[key] = fallback_value
                if fallback_value is not None:
                    self.memory_actor.store_memory_item(key, fallback_value)
        
        return result
    
    def _fetch_from_memory(self, key: str) -> Optional[Any]:
        """从智能体记忆中获取数据"""
        try:
            return self.memory_actor.retrieve_memory_item(key)
        except Exception as e:
            print(f"从记忆中获取数据失败: {e}")
            return None
    
    def _resolve_kv_via_layered_search(
        self,
        start_agent_id: str,
        query: str,
        key: str
    ) -> Optional[str]:
        """
        严格按照以下规则进行分层搜索：
        - 从start_agent所在层开始搜索
        - 每层进行语义匹配找到合适的节点
        - 如果匹配到叶子节点，直接返回该节点的code
        - 如果匹配到非叶子节点，继续向下一层搜索
        - 如果当前层无匹配，向上一层搜索
        - 直到找到叶子节点或到达根层
        """
        # 初始化：当前层 = start_agent 的兄弟层（含自己）
        current_agent = start_agent_id
        visited_layers = set()  # 防止循环（理论上不会，但安全）

        while True:
            parent = self.registry.get_parent(current_agent)
            if parent is None:
                current_layer = [current_agent]  # 根层
            else:
                current_layer = self.registry.get_children(parent)  # 当前层所有节点

            layer_key = tuple(sorted(current_layer))
            if layer_key in visited_layers:
                break  # 防死循环
            visited_layers.add(layer_key)

            # 收集当前层所有节点的描述信息
            node_desc = {}
            for node_id in current_layer:
                meta = self.registry.get_agent_meta(node_id)
                if not meta:
                    continue
                ds = meta.get("datascope", {})
                caps = meta.get("capability", [])
                ds_text = ds or "无数据字段"
                cap_text = caps if caps else "无能力声明"
                node_desc[node_id] = f"[节点 {node_id}] 数据: {ds_text}。能力: {cap_text}"
            
            # 使用Qwen进行语义匹配，找到最合适的节点
            matched_node_id = self._qwen_semantic_match_for_layer(query, node_desc)

            if matched_node_id is not None:
                # 有匹配！检查是否是叶子节点
                matched_meta = self.registry.get_agent_meta(matched_node_id)
                if matched_meta.get("is_leaf"):
                    # 找到叶子节点，返回其code
                    return matched_meta["code"]
                else:
                    # 非叶子节点：向下一层（进入它的direct children）
                    children = self.registry.get_children(matched_node_id)
                    if not children:
                        break  # 无子节点但又不是叶子，异常情况
                    # 下一次循环检查它的子层
                    current_agent = children[0]  # 任选一个子节点来定位层
                    continue
            else:
                # 当前层无匹配：向上一层
                if parent is None:
                    # 已是根层，再向上就没了
                    print("已到达根层，无匹配节点")
                    break
                else:
                    # 移动到父层：让current_agent = parent，下轮检查parent的兄弟层
                    current_agent = parent
                    continue

        return None
    
    def _qwen_semantic_match_for_layer(
        self,
        query: str,
        layer_nodes: Dict[str, str]
    ) -> Optional[str]:
        """使用Qwen判断当前层中哪个节点匹配查询"""
        if not layer_nodes:
            return None

        # 构造候选描述
        candidates_text = []
        node_id_list = []
        for node_id, desc in layer_nodes.items():
            candidates_text.append(desc)
            node_id_list.append(node_id)

        candidates_block = "\n".join(candidates_text)

        prompt = f"""你是一个数据路由语义匹配引擎。请根据以下数据需求，从候选数据节点中选择**最匹配的一个**。

数据需求:
{query}

候选节点:
{candidates_block}

请严格按照以下规则回答：
- 如果有匹配项，请只输出对应的 node_id（例如：C1）；
- 如果没有一个候选能合理满足该需求，请只输出 "none"。
- 不要解释，不要加标点，不要多余文字。
"""

        try:
            # 调用Qwen大模型进行语义匹配
            response = self._call_qwen(prompt)
            answer = response.strip()

            if answer.lower() == "none":
                return None

            # 检查返回的是否是合法node_id
            if answer in node_id_list:
                return answer
            else:
                # 可能模型返回了带引号或空格，尝试清理
                cleaned = answer.strip().strip('"').strip("'")
                if cleaned in node_id_list:
                    return cleaned
            return None
        except Exception as e:
            print(f"Qwen语义匹配失败: {e}")
            return None
    
    def _fetch_data_using_vanna(self, node_code: str, key: str, value_desc: str) -> Optional[Any]:
        """通过vanna从指定节点查询实际数据"""
        try:
            # 构建查询提示，明确指定从哪个节点查询数据
            query_prompt = f"从节点 {node_code} 查询变量 '{key}' 的值，描述为: '{value_desc}'"
            # 使用vanna进行查询
            vanna_result = self.vanna_integration.complete_and_query(query_prompt)
            return vanna_result.get(key)
        except Exception as e:
            print(f"通过vanna查询数据失败: {e}")
            return None
    
    def _vanna_general_query(self, context: Dict[str, str], key: str, value_desc: str) -> Optional[Any]:
        """作为后备方案，使用vanna进行通用查询"""
        try:
            query_prompt = f"基于上下文 {context}，查询变量 '{key}' 的值，描述为: '{value_desc}'"
            vanna_result = self.vanna_integration.complete_and_query(query_prompt)
            return vanna_result.get(key)
        except Exception as e:
            print(f"通用查询失败: {e}")
            return None
    
    def _call_qwen(self, prompt: str) -> str:
        """调用Qwen大模型"""
        llm = QwenLLM()
        return llm.generate(prompt)


**接口示例代码**：
```python
# data_analytics/data_interface.py
from abc import ABC, abstractmethod
from typing import Dict, Any, List

class DataAccessInterface(ABC):
    """数据访问抽象接口"""
    
    @abstractmethod
    def query(self, query_str: str, params: Dict[str, Any] = None) -> List[Dict[str, Any]]:
        """执行查询操作"""
        pass
    
    @abstractmethod
    def get_data_by_id(self, data_id: str, data_type: str) -> Dict[str, Any]:
        """根据ID获取数据"""
        pass
    
    @abstractmethod
    def update_data(self, data_id: str, data_type: str, updates: Dict[str, Any]) -> bool:
        """更新数据"""
        pass

# data_analytics/data_actor.py
from data_interface import DataAccessInterface
from business_data.mysql_business import MySQLBusinessData
from vanna.qwen_integration import QwenVannaIntegration

class DataAnalyticsActor(DataAccessInterface):
    """基于接口实现的数据访问组件"""
    
    def __init__(self):
        self.business_data = MySQLBusinessData()
        self.query_processor = self._init_query_processor()
        self.vanna_integration = QwenVannaIntegration()
    
    def query(self, query_str: str, params: Dict[str, Any] = None) -> List[Dict[str, Any]]:
        # 实现查询逻辑，可调用query_processor和vanna
        processed_query = self.query_processor.process(query_str, params)
        if self._requires_completion(processed_query):
            return self.vanna_integration.complete_and_query(processed_query)
        return self.business_data.execute_query(processed_query)
    
    # 其他接口方法实现...
    
    def _init_query_processor(self):
        # 初始化查询处理器
        from query_processor import QueryProcessor
        return QueryProcessor()
    
    def _requires_completion(self, query: str) -> bool:
        # 判断是否需要数据补全
        return True  # 简化实现
   - 基于agent/io模块重构，提供更灵活的数据操作能力
   - 采用插件化设计，支持未来替换为更高效的数据访问方案

**迁移示例**：
```python
# 能力基类定义
class CapabilityBase:
    def initialize(self):
        pass
    
    def get_capability_name(self):
        return self.__class__.__name__

# loop_queue/queue_interface.py 迁移示例
from abc import ABC, abstractmethod

class LoopQueueInterface(ABC):
    @abstractmethod
    def add_task(self, task, interval):
        """添加循环任务"""
        pass
    
    @abstractmethod
    def remove_task(self, task_id):
        """移除循环任务"""
        pass
    
    @abstractmethod
    def start(self):
        """启动循环队列"""
        pass
    
    @abstractmethod
    def stop(self):
        """停止循环队列"""
        pass

# loop_queue/thespian_queue.py 迁移示例
from capabilities.loop_queue.queue_interface import LoopQueueInterface
from thespian.actors import ActorSystem

class ThespianLoopQueue(LoopQueueInterface):
    def __init__(self):
        self.actor_system = None
        self.tasks = {}
    
    def initialize(self):
        self.actor_system = ActorSystem()
    
    def add_task(self, task, interval):
        # 实现与thespian兼容的任务添加逻辑
        task_id = id(task)
        self.tasks[task_id] = (task, interval)
        return task_id
    
    def remove_task(self, task_id):
        if task_id in self.tasks:
            del self.tasks[task_id]
    
    def start(self):
        # 启动循环执行器
        pass
    
    def stop(self):
        # 停止循环执行器
        if self.actor_system:
            self.actor_system.shutdown()

# loop_queue/queue_factory.py 迁移示例
def create_queue(queue_type="thespian", **kwargs):
    """创建循环队列实例
    
    Args:
        queue_type: 队列类型，默认为"thespian"
        **kwargs: 额外的配置参数
        
    Returns:
        LoopQueueInterface: 循环队列实例
    """
    if queue_type == "thespian":
        from capabilities.loop_queue.thespian_queue import ThespianLoopQueue
        queue = ThespianLoopQueue()
        queue.initialize()
        return queue
    else:
        raise ValueError(f"Unsupported queue type: {queue_type}")

# optimization/optimization_interface.py 迁移示例
from abc import ABC, abstractmethod

class OptimizationInterface(ABC):
    @abstractmethod
    def optimize_task(self, task, history_data):
        """优化任务执行"""
        pass
    
    @abstractmethod
    def learn_from_result(self, task_id, result, feedback):
        """从执行结果中学习"""
        pass

# multifeature/self_learning.py 迁移示例
from capabilities.optimization.optimization_interface import OptimizationInterface
from capabilities.multifeature.inference import induction, deduction

class MultifeatureOptimizer(OptimizationInterface):
    def __init__(self):
        # 初始化学习模型和知识库
        self.knowledge_base = None
    
    def initialize(self):
        # 初始化自学习组件
        from multifeature.belief_revision import KnowledgeBase
        self.knowledge_base = KnowledgeBase()
    
    def optimize_task(self, task, history_data):
        # 利用归纳和演绎进行任务优化
        optimized_params = induction(history_data)
        return optimized_params
    
    def learn_from_result(self, task_id, result, feedback):
        # 从执行结果和反馈中学习
        new_rules = deduction(result, feedback)
        self.knowledge_base.add_rules(new_rules)

# llm_memory_system/manager.py 迁移示例
class MemoryCapability(CapabilityBase):
    def __init__(self):
        # 从 UnifiedMemoryManager 迁移核心逻辑
        self.short_term = None
        self.long_term = None
    
    def initialize(self):
        # 初始化记忆组件
        pass
```

### 3.4 能力 actor 层（capability_actors/）

**功能**：作为底层能力与actor系统之间的转换层

**文件结构**：
```
capability_actors/
├── __init__.py
├── memory_actor.py     # 从agent/memory/memory_actor.py迁移
├── data_actor.py       # 从agent/io/data_actor.py迁移，集成并使用data_analytics层的功能
├── mcp_actor.py        # 从agent/mcp/mcp_actor.py迁移
└── dify_actor.py       # 从agent/excute/dify_actor.py迁移
```

**迁移示例**：
```python
# agent/memory/memory_actor.py 迁移到 capability_actors/memory_actor.py
class MemoryActor(Actor):
    def __init__(self):
        # 保持原有结构
        self.manager = None
        # 但现在从 capabilities.llm_memory.manager 导入
        from capabilities.llm_memory.manager import UnifiedMemoryManager
    
    # receiveMessage 方法保持不变，但内部实现可以简化
    # 因为底层能力已经被封装为能力组件
```

### 3.5 agent_actor 层（agents/）

**功能**：系统核心，负责任务处理、决策和向下传递

**文件结构**：
```
agents/
├── __init__.py
├── agent_actor.py      # 重构自现有agent_actor.py，集成并行执行管理器
├── tree/               # 基于现有agent_registry.py
│   ├── __init__.py
│   ├── tree_manager.py     # 封装AgentRegistry功能
│   ├── node_service.py     # 节点管理服务
│   └── relationship_service.py  # 关系管理服务
├── execution/          # 执行相关
│   ├── __init__.py
│   ├── task_processor.py
│   └── result_aggregator.py  # 从coordination/result_aggregator.py迁移
├── coordination/       # 保留协调核心功能
│   ├── __init__.py
│   └── swarm_coordinator.py  # 从coordination/swarm_coordinator.py迁移
├── parallel/           # 并行执行
│   ├── __init__.py
│   ├── orchestrator.py     # 从concurrent_actor.py迁移并重构
│   ├── dimension_parser.py # 从llm_demension_parser.py迁移
│   └── execution_manager.py # 新建：并行执行管理器

```

**迁移与重构重点**：

1. **AgentActor重构**：
   ```python
   class AgentActor(Actor):
       def __init__(self):
           # 保留原有属性
           self.agent_id = ""
           # 但将并行执行逻辑集成进来，不再依赖外部VideoWorker
           from .parallel.orchestrator import ParallelOrchestrator
           self.parallel_orchestrator = None
       
       def _execute_intermediate(self, parent_task_id, context, original_sender):
           # 使用新的并行执行框架，替代原来的VideoWorker
           if self.parallel_orchestrator is None:
               self.parallel_orchestrator = self.createActor(ParallelOrchestrator)
           # 直接使用AgentActor作为执行单元
   ```

2. **TaskCoordinator拆分**：
   ```python
   # 1. task_router.py - 负责任务路由
   class TaskRouter:
       def select_best_actor(self, agent_id, context):
           # 从TaskCoordinator._select_best_actor迁移代码
           pass
   
   # 2. task_planner.py - 负责任务规划
   class TaskPlanner:
       def plan_subtasks(self, parent_agent_id, context):
           # 从TaskCoordinator.plan_subtasks迁移代码
           pass
   
   # 3. context_resolver.py - 负责上下文解析
   class ContextResolver:
       def resolve_context(self, ctx, agent_id):
           # 从TaskCoordinator.resolve_context迁移代码
           pass
   ```

3. **并行执行机制修复**：
   ```python
   # parallel/orchestrator.py - 重构自concurrent_actor.py
   class ParallelOrchestrator(Actor):
       def receiveMessage(self, msg, sender):
           if msg.get("type") == "run_batch":
               # 不再创建不存在的VideoWorker
               # 直接使用AgentActor作为执行单元
               for inst, tnum in zip(msg["instructions"], msg["trial_numbers"]):
                   # 发送给对应的AgentActor执行
                   self.send(sender, {"trial_result": True, "trial_number": tnum, "script": result})
   ```

### 3.6 事件报告层（events/）

**功能**：统一的事件发布和订阅机制

**文件结构**：
```
events/
├── __init__.py
├── event_bus.py        # 新建：事件总线
├── event_types.py      # 新建：事件类型定义
├── subscriber.py       # 新建：订阅者接口
├── publisher.py        # 新建：发布者接口
├── event_actor.py      # 从observer_actor.py迁移并重构
└── task_event.py       # 从Observer/task_event.py迁移并扩展
```

**迁移示例**：
```python
# Observer/observer_actor.py 迁移到 events/event_actor.py
class EventActor(Actor):
    def __init__(self):
        from .event_bus import EventBus
        self.event_bus = EventBus.get_instance()
    
    def receiveMessage(self, msg, sender):
        # 将消息转发到事件总线
        if isinstance(msg, TaskEvent):
            self.event_bus.publish("task_event", msg)
```

### 3.7 公共配置与工具（common/）

**功能**：提供公共配置、工具类和常量定义

**文件结构**：
```
common/
├── __init__.py
├── config/             # 配置管理
│   ├── config_manager.py
│   └── plugin_config.py
├── utils/              # 工具函数
│   ├── __init__.py
│   ├── logger.py
│   └── serializer.py
└── messages/           # 从agent/message.py拆分
    ├── __init__.py
    ├── base_message.py
    ├── task_messages.py
    └── optimization_messages.py
```

**迁移示例**：
```python
# agent/message.py 拆分到 common/messages/
# common/messages/base_message.py
class MessageBase:
    pass

# common/messages/task_messages.py
class TaskMessage(MessageBase):
    def __init__(self, task_id, context):
        self.task_id = task_id
        self.context = context
```

## 4. 核心功能迁移实现

### 4.1 树形结构管理迁移

将现有 AgentRegistry 功能迁移到 agents/tree/ 目录：

```python
# agents/tree/node_service.py
class NodeService:
    def __init__(self, neo4j_adapter):
        self.adapter = neo4j_adapter
    
    def load_node(self, node_id):
        # 从 AgentRegistry.get_agent_meta 迁移
        pass
    
# agents/tree/relationship_service.py
class RelationshipService:
    def __init__(self, neo4j_adapter):
        self.adapter = neo4j_adapter
    
    def get_children(self, node_id):
        # 从 AgentRegistry.get_children 迁移
        pass
```

### 4.2 并行执行机制修复

修复现有 VideoWorker 问题，直接使用 AgentActor 作为执行单元：

```python
# agents/parallel/execution_manager.py
class ExecutionManager:
    def __init__(self, registry):
        self.registry = registry
    
    def execute_parallel_tasks(self, tasks, agent_ids):
        # 直接使用agent_ids对应的AgentActor执行任务
        # 不再创建不存在的VideoWorker
        results = {}
        for task, agent_id in zip(tasks, agent_ids):
            # 获取AgentActor引用并发送任务
            actor_ref = self.registry.get_actor_ref(agent_id)
            # 发送任务并收集结果
        return results
```

### 4.3 数据访问层重构

整合现有数据访问逻辑，支持多数据库和多模型：

```python
# agents/data/db_factory.py
class DatabaseFactory:
    @staticmethod
    def create_database_adapter(db_type, config):
        if db_type == "mysql":
            from external.database.mysql_adapter import MySQLAdapter
            return MySQLAdapter(config)
        elif db_type == "neo4j":
            from external.database.neo4j_adapter import Neo4jAdapter
            return Neo4jAdapter(**config)
        # 其他数据库类型
```

## 5. 迁移步骤与实施计划

### 5.1 准备阶段
1. 创建新的目录结构
2. 创建适配器基类和接口定义
3. 实现数据库适配器层

### 5.2 核心迁移阶段
1. 迁移能力组件到 capabilities/
2. 迁移能力Actor到 capability_actors/
3. 拆分TaskCoordinator为三个组件
4. 重构并行执行机制
5. 迁移和扩展事件系统

### 5.3 整合阶段
1. 更新AgentActor以使用新的组件
2. 实现统一的消息系统
3. 创建入口层组件
4. 更新全局初始化逻辑

### 5.4 测试与验证阶段
1. 单元测试各组件
2. 集成测试系统功能
3. 性能测试并行执行机制
4. 验证树形结构管理功能

## 6. 技术栈与依赖

| 类别 | 技术/库 | 用途 | 迁移注意事项 |
|------|---------|------|------------|
| 主要语言 | Python | 核心开发语言 | 保持不变 |
| 数据库 | MySQL, Neo4j | 数据存储 | 通过适配器模式统一访问 |
| LLM | Qwen | 语言模型 | 封装为底层能力 |
| 向量数据库 | ChromaDB | 记忆系统 | 集成到记忆能力中 |
| Actor框架 | Thespian | Actor模型实现 | 保持不变，但优化使用方式 |
| 图处理 | NetworkX | 依赖图分析 | 迁移到任务规划组件 |
| 外部服务 | Dify | 工作流执行 | 封装为适配器 |

## 7. 迁移注意事项与最佳实践

1. **保持接口兼容**：在迁移过程中，确保核心接口保持兼容，便于渐进式迁移
2. **优先迁移底层组件**：先迁移底层能力和外部对接层，再迁移上层组件
3. **分阶段测试**：每迁移一个组件就进行测试，确保功能正常
4. **日志记录**：在关键迁移点添加详细日志，便于调试
5. **备份现有代码**：迁移前对现有代码进行备份，防止意外情况
6. **文档更新**：及时更新API文档和使用说明

本适配版重构后架构文档提供了从现有Flora系统代码到重构后架构的详细映射关系和迁移指南，确保系统能够平滑过渡到新的架构设计，同时保持功能完整性和稳定性。