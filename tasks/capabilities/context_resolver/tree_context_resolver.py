"""ä¸Šä¸‹æ–‡è§£æå™¨å®ç°"""
from typing import Dict, Any, List, Optional, Tuple
from ..capability_base import CapabilityBase
import logging
import json
import re
from .interface import IContextResolverCapbility 
import logging
logger = logging.getLogger(__name__)

class TreeContextResolver(IContextResolverCapbility):
    """
    å…·ä½“çš„å®ç°ç±»ï¼š
    ä¸ TreeManager é›†æˆï¼Œåˆ©ç”¨æ ‘å½¢ç»“æ„è¿›è¡Œè¯­ä¹‰åŒ–çš„å±‚çº§æœç´¢ã€‚
    """

    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.config = {}
        
        # ä¾èµ–é¡¹ï¼šç°åœ¨ä½¿ç”¨ tree_manager
        self.tree_manager = None 
        self.llm_client = None
        
        self.variable_pattern = re.compile(r'\$\{([^}]+)\}')
        self.context_templates = {}

    def get_capability_type(self) -> str:
        return 'tree_context_resolver'

    def initialize(self, config: Dict[str, Any]) -> None:
        self.config = config
        self.logger.info("TreeContextResolver initialized with config.")

    def shutdown(self) -> None:
        self.context_templates.clear()
        self.tree_manager = None
        self.logger.info("TreeContextResolver shutdown.")

    def set_dependencies(self, tree_manager: Any=None, llm_client: Any = None) -> None:
        """
        æ³¨å…¥ TreeManager å•ä¾‹å’Œ LLM å®¢æˆ·ç«¯
        """
        if tree_manager:
            self.tree_manager = tree_manager
        else:
            from ...agents.tree.tree_manager import treeManager
            self.tree_manager=treeManager
        if llm_client:
            self.llm_client = llm_client
        else:
            from ..llm.interface import ILLMCapability
            from .. import get_capability
            self.llm_client:ILLMCapability = get_capability("llm",ILLMCapability)
        
        self.logger.info("Dependencies (TreeManager, LLM) injected.")

    # ----------------------------------------------------------
    # æ ¸å¿ƒé€»è¾‘ï¼šåŸºäº TreeManager çš„å¯»å€
    # ----------------------------------------------------------

    def resolve_context(self, context_requirements: Dict[str, str], agent_id: str) -> Dict[str, Any]:
        """
        è§£æä¸Šä¸‹æ–‡éœ€æ±‚ï¼š
        1. å…ˆé€šè¿‡ _resolve_kv_via_layered_search å®šä½æ•°æ®æ‰€åœ¨ä½ç½®ï¼ˆåº“/è¡¨/åˆ—ï¼‰ï¼›
        2. è‹¥å®šä½æˆåŠŸï¼Œåˆ™ä½¿ç”¨ VannaTextToSQL æ‰§è¡ŒçœŸå®æŸ¥è¯¢ï¼Œè¿”å›å®é™…æ•°æ®ã€‚
        """
        if not self.tree_manager or not self.llm_client:
            self.set_dependencies()

        result = {}
        try:
            path = self.tree_manager.get_full_path(agent_id)
            path_str = " -> ".join(path)
        except:
            path_str = agent_id

        self.logger.info(f"Start resolving context for agent: {agent_id} (Path: {path_str})")

        # è·å–å½“å‰ Agent çš„åŸºç¡€å…ƒä¿¡æ¯ï¼ˆç”¨äº fallback æˆ–æ—¥å¿—ï¼‰
        base_agent_meta = {}
        try:
            base_agent_meta = self.tree_manager.get_agent_meta(agent_id) or {}
        except Exception as e:
            self.logger.warning(f"Could not retrieve base agent meta for {agent_id}: {e}")

        for key, value_desc in context_requirements.items():
            try:
                query = f"éœ€æŸ¥æ‰¾æ•°æ®: '{key}', ä¸šåŠ¡æè¿°: '{value_desc}'"
                
                # Step 1: å®šä½æ•°æ®ä½ç½®ï¼ˆåº“ã€è¡¨ã€åˆ—ç­‰ï¼‰
                leaf_meta = self._resolve_kv_via_layered_search(agent_id, query, key)
                
                if not leaf_meta:
                    self.logger.warning(f"âŒ Unresolved '{key}' (Desc: {value_desc}) â€“ no location found")
                    result[key] = None
                    continue

                # Step 2: å¦‚æœå®šä½æˆåŠŸï¼Œå°è¯•ç”¨ Vanna æŸ¥è¯¢çœŸå®æ•°æ®
                self.logger.info(f"ğŸ“ Located '{key}' at: {leaf_meta}")
                
                # æ„é€  Vanna æ‰€éœ€çš„ agent_meta æ ¼å¼ï¼šdatabase = "db.table"
                db_name = leaf_meta.get("database") or leaf_meta.get("db")
                table_name = leaf_meta.get("table") or leaf_meta.get("tbl")
                
                if not db_name or not table_name:
                    self.logger.warning(f"âš ï¸ Incomplete location info for '{key}': {leaf_meta}, skip Vanna query")
                    result[key] = leaf_meta  # æˆ–è®¾ä¸º Noneï¼ŒæŒ‰éœ€
                    continue

                vanna_agent_meta = {
                    "database": f"{db_name}.{table_name}",
                    "database_type": leaf_meta.get("database_type", base_agent_meta.get("database_type", "mysql"))
                }

                # åˆå§‹åŒ– Vanna èƒ½åŠ›
                from ..registry import capability_registry
                from ..text_to_sql.text_to_sql import ITextToSQLCapability
                text_to_sql_cap: ITextToSQLCapability = capability_registry.get_capability(
                    "text_to_sql", expected_type=ITextToSQLCapability
                )

                text_to_sql_cap.initialize({
                    "agent_id": agent_id,
                    "agent_meta": vanna_agent_meta
                })

                try:
                    # ä½¿ç”¨åŸå§‹ä¸šåŠ¡æè¿°ä½œä¸ºæŸ¥è¯¢è¯­å¥
                    response = text_to_sql_cap.execute_query(user_query=value_desc, context=None)
                    records = response.get("result", [])
                    
                    if records:
                        # å‡è®¾è¿”å›çš„æ˜¯å•å€¼æˆ–å•è¡Œï¼Œå¯æŒ‰éœ€è°ƒæ•´
                        resolved_value = records[0] if len(records) == 1 else records
                        result[key] = resolved_value
                        self.logger.info(f"âœ… Resolved '{key}' with real data (rows: {len(records)})")
                    else:
                        self.logger.warning(f"ğŸ” Located but no data returned for '{key}'")
                        result[key] = None  # æˆ–ä¿ç•™ leaf_metaï¼Œè§†ä¸šåŠ¡è€Œå®š
                        
                finally:
                    # ç¡®ä¿é‡Šæ”¾èµ„æº
                    text_to_sql_cap.shutdown()

            except Exception as e:
                self.logger.error(f"Error resolving key '{key}': {str(e)}", exc_info=True)
                result[key] = None

        return result

    def _resolve_kv_via_layered_search(self, start_agent_id: str, query: str, key: str) -> Optional[Dict]:
        """
        é€‚é… TreeManager çš„å±‚çº§æœç´¢ç®—æ³•
        """
        # 1. åˆå§‹å®šä½ï¼šè·å– start_agent çš„çˆ¶èŠ‚ç‚¹ï¼Œä»¥ç¡®å®šåˆå§‹çš„"å…„å¼Ÿå±‚"
        parent_id = self.tree_manager.get_parent(start_agent_id)
        
        # ç”¨äºé˜²æ­¢æ­»å¾ªç¯ï¼ˆè™½ç„¶ TreeManager å†…éƒ¨æœ‰é˜²ç¯ï¼Œä½†æœç´¢é€»è¾‘å±‚ä¹Ÿä¿ç•™ä¸€ä»½ä¿é™©ï¼‰
        visited_layers = set()
        
        # è®°å½•å½“å‰è§†è§’çš„èŠ‚ç‚¹ï¼Œç”¨äºå‘ä¸Šå›æº¯æ—¶å®šä½
        current_focus_node = start_agent_id

        while True:
            # --- 1. ç¡®å®šå½“å‰æœç´¢å±‚ (Layer) ---
            if parent_id is None:
                # æ ¸å¿ƒå˜æ›´ï¼šåˆ©ç”¨ TreeManager.get_root_agents() è·å–æ ¹å±‚
                self.logger.debug(f"Searching Root Layer for: {key}")
                current_layer = self.tree_manager.get_root_agents()
                
                # å¦‚æœå½“å‰èšç„¦çš„èŠ‚ç‚¹æœ¬èº«å°±æ˜¯æ ¹èŠ‚ç‚¹ï¼Œä¸”åœ¨æ ¹å±‚ä¹Ÿæ‰¾ä¸åˆ°ï¼Œå¾ªç¯é€šå¸¸ä¼šåœ¨åé¢ Break
            else:
                # è·å–çˆ¶èŠ‚ç‚¹çš„æ‰€æœ‰å­èŠ‚ç‚¹ï¼ˆå³å½“å‰å±‚ï¼‰
                current_layer = self.tree_manager.get_children(parent_id)

            # --- é˜²æ­»å¾ªç¯æ£€æŸ¥ ---
            layer_sig = tuple(sorted(current_layer))
            if layer_sig in visited_layers:
                self.logger.warning("Cycle detected in search layer. Stopping.")
                break
            visited_layers.add(layer_sig)

            # --- 2. åœ¨å½“å‰å±‚è¿›è¡Œè¯­ä¹‰åŒ¹é… ---
            matched_node_id = self._semantic_match_for_layer(query, current_layer)

            # --- 3. åŒ¹é…ç»“æœå¤„ç† ---
            if matched_node_id:
                # >> å‘½ä¸­åˆ†æ”¯ >>
                # ä½¿ç”¨ TreeManager è·å–å…ƒæ•°æ®
                node_meta = self.tree_manager.get_agent_meta(matched_node_id)
                
                # ä½¿ç”¨ TreeManager åˆ¤æ–­æ˜¯å¦å¶å­
                is_leaf = self.tree_manager.is_leaf_agent(matched_node_id)
                
                self.logger.debug(f"Match found: {matched_node_id} (Is Leaf: {is_leaf})")

                if is_leaf:
                    # æƒ…å†µ A: æ‰¾åˆ°å¶å­èŠ‚ç‚¹ -> æˆåŠŸ
                    return node_meta
                else:
                    # æƒ…å†µ B: ä¸­é—´èŠ‚ç‚¹ -> å‘ä¸‹é’»å– (Drill Down)
                    children = self.tree_manager.get_children(matched_node_id)
                    if not children:
                        break # æ­»èƒ¡åŒ
                    
                    # è§†è§’ä¸‹æ²‰ï¼šæ–°çš„çˆ¶èŠ‚ç‚¹æ˜¯åˆšæ‰åŒ¹é…åˆ°çš„èŠ‚ç‚¹
                    parent_id = matched_node_id
                    # (current_focus_node åœ¨å‘ä¸‹é’»å–æ—¶å…¶å®ä¸é‡è¦ï¼Œå› ä¸ºä¸‹ä¸€è½®ç›´æ¥å– parent çš„ children)
                    continue
            else:
                # >> æœªå‘½ä¸­åˆ†æ”¯ >>
                # æƒ…å†µ C: å½“å‰å±‚æ— åŒ¹é… -> å‘ä¸Šå›æº¯ (Bubble Up)
                if parent_id is None:
                    # å·²ç»åœ¨æ ¹å±‚ä¸”æœªå‘½ä¸­ -> æœç´¢å…¨é¢å¤±è´¥
                    self.logger.debug("Reached root layer with no match.")
                    break
                
                # ç§»åŠ¨è§†è§’å‘ä¸Šï¼š
                # æˆ‘ä»¬è¦æ‰¾ parent çš„å…„å¼Ÿï¼Œæ‰€ä»¥å°†è§†è§’èšç„¦åˆ° parent
                current_focus_node = parent_id
                # è·å– parent çš„ parent
                parent_id = self.tree_manager.get_parent(current_focus_node)
                continue
        
        return None

    def _semantic_match_for_layer(self, query: str, node_ids: List[str]) -> Optional[str]:
        """
        [é‡æ„å] ä½¿ç”¨ DashScope Qwen åˆ¤æ–­å½“å‰å±‚ä¸­å“ªä¸ªèŠ‚ç‚¹åŒ¹é… queryã€‚
        
        Args:
            query: è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼Œå¦‚ "éœ€æŸ¥æ‰¾æ•°æ®: 'user_id', ä¸šåŠ¡æè¿°: 'å½“å‰ç™»å½•ç”¨æˆ·'"
            node_ids: å½“å‰å±‚çš„èŠ‚ç‚¹IDåˆ—è¡¨ (List[str])
        
        Returns:
            åŒ¹é…çš„ node_id (str)ï¼Œè‹¥æ— åŒ¹é…è¿”å› None
        """
        if not node_ids:
            return None

        # 1. å‡†å¤‡å€™é€‰èŠ‚ç‚¹æ•°æ®
        candidates_text = []
        valid_node_ids = [] # ç”¨äºåç»­æ ¡éªŒ LLM è¿”å›çš„ ID æ˜¯å¦åˆæ³•

        for nid in node_ids:
            # ä» TreeManager è·å–å…ƒæ•°æ®
            meta = self.tree_manager.get_agent_meta(nid)
            if not meta:
                continue

            # æå–å…³é”®ä¿¡æ¯ï¼Œæ„å»ºè¯­ä¹‰æè¿°
            # ä¼˜å…ˆå– datascopeï¼Œå…¶æ¬¡æ˜¯ capabilityï¼Œæœ€åæ˜¯ description
            ds = meta.get("datascope") or meta.get("data_scope") or "æ— æ•°æ®åŸŸå®šä¹‰"
            caps = meta.get("capability") or meta.get("capabilities") or []
            desc_text = meta.get("description", "")

            # æ ¼å¼åŒ–å„ä¸ªå­—æ®µ
            ds_str = str(ds) if isinstance(ds, (dict, list)) else str(ds)
            cap_str = ", ".join(caps) if isinstance(caps, list) else str(caps)

            # ç»„åˆæˆä¸€æ®µåˆ©äº LLM ç†è§£çš„æ–‡æœ¬
            # æ ¼å¼: [ID] æ•°æ®: ...; èƒ½åŠ›: ...; æè¿°: ...
            node_desc = (
                f"å€™é€‰èŠ‚ç‚¹ID: {nid}\n"
                f"  - æ•°æ®èŒƒå›´: {ds_str}\n"
                f"  - èƒ½åŠ›å£°æ˜: {cap_str}\n"
                f"  - èŠ‚ç‚¹æè¿°: {desc_text}"
            )
            
            candidates_text.append(node_desc)
            valid_node_ids.append(nid)

        if not candidates_text:
            return None

        candidates_block = "\n\n".join(candidates_text)

        # 2. æ„é€  Prompt
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼ç³»ç»Ÿçš„æ•°æ®è·¯ç”±è¯­ä¹‰åŒ¹é…å¼•æ“ã€‚è¯·æ ¹æ®ä»¥ä¸‹æ•°æ®éœ€æ±‚ï¼Œä»å€™é€‰èŠ‚ç‚¹åˆ—è¡¨ä¸­é€‰æ‹©**æœ€åŒ¹é…çš„ä¸€ä¸ª**ã€‚

æ•°æ®éœ€æ±‚:
{query}

å€™é€‰èŠ‚ç‚¹åˆ—è¡¨:
---
{candidates_block}
---

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è§„åˆ™å›ç­”ï¼š
1. åˆ†æå“ªä¸ªèŠ‚ç‚¹çš„"æ•°æ®èŒƒå›´"æˆ–"èŠ‚ç‚¹æè¿°"èƒ½è¦†ç›–ä¸Šè¿°æ•°æ®éœ€æ±‚ã€‚
2. å¦‚æœæœ‰åŒ¹é…é¡¹ï¼Œè¯·åªè¾“å‡ºå¯¹åº”çš„ **èŠ‚ç‚¹ID** (ä¾‹å¦‚: user_agent_01)ã€‚
3. å¦‚æœæ²¡æœ‰ä¸€ä¸ªå€™é€‰èƒ½åˆç†æ»¡è¶³è¯¥éœ€æ±‚ï¼Œæˆ–è€…ç›¸å…³æ€§æä½ï¼Œè¯·åªè¾“å‡º "none"ã€‚
4. ä¸è¦è§£é‡Šï¼Œä¸è¦åŠ æ ‡ç‚¹ï¼Œä¸è¦åŒ…å«ä»»ä½•å¤šä½™æ–‡å­—ã€‚
"""

        # 3. è°ƒç”¨ LLM
        try:
            # å‡è®¾ self.llm_client å·²ç»åˆå§‹åŒ–å¹¶æ³¨å…¥
            # å¦‚æœä½ ç”¨çš„æ˜¯ requests æˆ–ç‰¹å®šçš„ SDKï¼Œåœ¨è¿™é‡Œæ›¿æ¢å³å¯
            if not self.llm_client:
                self.logger.warning("LLM client missing, falling back to keyword match.")
                return self._fallback_keyword_match(query, valid_node_ids)

            # è°ƒç”¨å¤§æ¨¡å‹ (è¿™é‡Œæ¨¡æ‹Ÿä½ çš„ call_qwen é€»è¾‘)
            # answer = self.call_qwen(prompt) 
            answer = self.llm_client.generate(prompt) 
            
            # æ¸…ç†ç»“æœ
            answer = answer.strip().replace("'", "").replace('"', "").replace("`", "")
            
            self.logger.info(f"Qwen semantic match result: '{answer}' for query: '{query}'")

            # 4. ç»“æœæ ¡éªŒ
            if answer.lower() == "none":
                return None

            if answer in valid_node_ids:
                return answer
            else:
                self.logger.warning(f"Qwen returned invalid node_id: '{answer}'. Expected one of: {valid_node_ids}")
                return None

        except Exception as e:
            self.logger.error(f"Exception calling LLM/DashScope: {e}", exc_info=True)
            # é™çº§ç­–ç•¥
            return self._fallback_keyword_match(query, valid_node_ids)

    def _fallback_keyword_match(self, query: str, node_ids: List[str]) -> Optional[str]:
        """
        ç®€å•çš„å…³é”®è¯åŒ¹é…å…œåº•ç­–ç•¥
        """
        import re
        # æå–æŸ¥è¯¢ä¸­çš„å…³é”®è¯ï¼ˆå¿½ç•¥æ ‡ç‚¹ï¼‰
        keywords = set(re.findall(r'[\w\u4e00-\u9fa5]+', query))
        best_node = None
        max_score = 0

        for nid in node_ids:
            meta = self.tree_manager.get_agent_meta(nid) or {}
            # å°†æ‰€æœ‰å…ƒæ•°æ®è½¬ä¸ºå­—ç¬¦ä¸²è¿›è¡Œæœç´¢
            content = (
                str(meta.get("datascope", "")) + 
                str(meta.get("description", "")) + 
                str(meta.get("capability", ""))
            ).lower()
            
            score = sum(1 for kw in keywords if kw.lower() in content)
            
            if score > max_score:
                max_score = score
                best_node = nid
        
        return best_node if max_score > 0 else None





    def enhance_param_descriptions_with_context(
        self,
        base_param_descriptions: dict,
        current_inputs: dict
        ) -> dict:
        """
        ä½¿ç”¨ LLM å°†åŸºç¡€å‚æ•°æè¿°å¢å¼ºä¸ºâ€œå¸¦ä¸Šä¸‹æ–‡â€çš„æè¿°ã€‚
        
        Args:
            base_param_descriptions: dict, e.g. {"template_id": "æµ·æŠ¥æ¨¡æ¿ID"}
            current_inputs: dict, e.g. {"tenant_id": "t_abc", "activity_id": "act_123"}
        
        Returns:
            dict: {"template_id": "æµ·æŠ¥æ¨¡æ¿IDï¼Œå±äºç§Ÿæˆ· t_abc å’Œæ´»åŠ¨ act_123"}
        """
        if not base_param_descriptions:
            return {}
        
        if not self.tree_manager or not self.llm_client:
            self.set_dependencies()

        # æ„å»ºä¸Šä¸‹æ–‡å­—ç¬¦ä¸²ï¼ˆåªä¿ç•™éç©ºã€éæ•æ„Ÿå­—æ®µï¼Œå¯æ‰©å±•è¿‡æ»¤é€»è¾‘ï¼‰
        context_items = []
        for k, v in current_inputs.items():
                
            # 2. ç±»å‹å®‰å…¨æ£€æŸ¥
            if not v or not isinstance(v, (str, int, float, bool)):
                continue
                
            v_str = str(v)
            
            # 3. æ”¾å®½é•¿åº¦é™åˆ¶ï¼šå»ºè®®ä» 100 æå‡åˆ° 500 æˆ– 1000
            # è¿™æ ·æ—¢èƒ½é˜²ä½å‡ ä¸‡å­—çš„è¶…å¤§æ–‡æœ¬ï¼Œåˆèƒ½å®¹çº³ URL å’Œ ä¸šåŠ¡æè¿°
            if len(v_str) < 1000:  
                context_items.append(f"{k}: {v_str}")
            else:
                # å¯é€‰ï¼šå¯¹äºè¶…é•¿æ–‡æœ¬ï¼Œæˆªå–å‰ 100 ä¸ªå­—ç¬¦ä½œä¸ºâ€œæ‘˜è¦â€æ”¾è¿›å»
                # è¿™æ · LLM è‡³å°‘çŸ¥é“æœ‰è¿™ä¸ªå­—æ®µå­˜åœ¨
                context_items.append(f"{k}: {v_str[:100]}... (content too long)")
        
        context_str = "\n".join(context_items) if context_items else "æ— å¯ç”¨ä¸Šä¸‹æ–‡"

        # æ„å»ºå‚æ•°åˆ—è¡¨å­—ç¬¦ä¸²
        params_list = "\n".join([
            f"- {name}: {desc}" 
            for name, desc in base_param_descriptions.items()
        ])

        # === æ„å»º LLM Prompt ===
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½å‚æ•°æè¿°å¢å¼ºå™¨ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ï¼Œä¸ºæ¯ä¸ªå‚æ•°ç”Ÿæˆå¢å¼ºç‰ˆçš„ä¸­æ–‡æè¿°ã€‚

    è¦æ±‚ï¼š
    - è¾“å‡ºå¿…é¡»æ˜¯ä¸¥æ ¼çš„ JSON æ ¼å¼ï¼š{{ "å‚æ•°å": "å¢å¼ºåçš„æè¿°" }}
    - åœ¨åŸå§‹æè¿°åŸºç¡€ä¸Šï¼Œ**è‡ªç„¶èå…¥æ‰€æœ‰å¯ç”¨çš„ä¸Šä¸‹æ–‡ä¿¡æ¯**ï¼ˆå¦‚ tenant_idã€activity_id ç­‰ï¼‰
    - ä¸Šä¸‹æ–‡ä¿¡æ¯ç”¨äºå¸®åŠ©åç»­ç³»ç»Ÿç²¾å‡†æŸ¥è¯¢è¯¥å‚æ•°å€¼ï¼Œè¯·æ˜ç¡®å†™å‡ºå½’å±ï¼ˆä¾‹å¦‚ï¼šâ€œå±äºç§Ÿæˆ·xxxx çš„æ´»åŠ¨ xxxxâ€ï¼‰
    - å¦‚æœæŸä¸ªä¸Šä¸‹æ–‡ä¸å‚æ•°æ˜æ˜¾æ— å…³ï¼Œå¯ä¸å¼ºè¡ŒåŠ å…¥
    - æè¿°è¦ç®€æ´ã€ä¸“ä¸šã€å¯è¢«è‡ªåŠ¨åŒ–ç³»ç»Ÿç†è§£
    - **ä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„ä¸Šä¸‹æ–‡**
    - **ä¸è¦æ”¹å˜å‚æ•°å**
    - åªè¾“å‡º JSONï¼Œä¸è¦ä»»ä½•å…¶ä»–æ–‡å­—

    ã€å¯ç”¨ä¸Šä¸‹æ–‡ã€‘
    {context_str}

    ã€å¾…å¢å¼ºçš„å‚æ•°åŠåŸºç¡€æè¿°ã€‘
    {params_list}
    """

        # === è°ƒç”¨ LLM ===
        try:
            response = self.llm_client.generate(
                prompt=prompt,
                parse_json=True,
            )
            result = response


            # ä¿è¯è¾“å‡º key ä¸è¾“å…¥ä¸€è‡´ï¼ˆé˜²æ­¢ LLM æ”¹åï¼‰
            aligned_result = {}
            for param_name in base_param_descriptions:
                if param_name in result:
                    aligned_result[param_name] = str(result[param_name]).strip()
                else:
                    # å›é€€ï¼šç”¨åŸå§‹æè¿° + ä¸Šä¸‹æ–‡æ‹¼æ¥ï¼ˆä¿å®ˆç­–ç•¥ï¼‰
                    fallback_desc = base_param_descriptions[param_name]
                    if context_items:
                        fallback_desc += "ï¼Œä¸Šä¸‹æ–‡ï¼š" + "ï¼›".join(context_items)
                    aligned_result[param_name] = fallback_desc

            return aligned_result

        except Exception as e:
            print(f"[WARN] LLM å¢å¼ºå¤±è´¥ï¼Œä½¿ç”¨å›é€€ç­–ç•¥: {e}")
            # å…¨éƒ¨å›é€€åˆ°åŸºç¡€æè¿° + ä¸Šä¸‹æ–‡æ‹¼æ¥
            fallback = {}
            context_suffix = "ï¼ˆä¸Šä¸‹æ–‡ï¼š" + "ï¼›".join(context_items) + "ï¼‰" if context_items else ""
            for name, desc in base_param_descriptions.items():
                fallback[name] = desc + context_suffix
            return fallback



    def pre_fill_known_params_with_llm(
        self,
        base_param_descriptions: dict,
        current_context_str: str
    ) -> tuple[dict, dict]:
        """
        ä½¿ç”¨ LLM ä»è‡ªç”±æ–‡æœ¬ä¸Šä¸‹æ–‡ä¸­æå–å¯è¯†åˆ«çš„å‚æ•°å€¼ã€‚
        
        Args:
            base_param_descriptions: {"user_id": "ç”¨æˆ·ID", "tenant_id": "ç§Ÿæˆ·ID", ...}
            current_context_str: ä»»æ„ä¸Šä¸‹æ–‡ï¼Œå¦‚ "å½“å‰ç”¨æˆ·æ˜¯ test_admin_001ï¼Œå±äºç§Ÿæˆ· test_tenant_001"
        
        Returns:
            (filled_values, remaining_params)
        """
        if not base_param_descriptions:
            return {}, {}
        
        if not self.tree_manager or not self.llm_client:
            self.set_dependencies()

        # æ„å»ºå‚æ•°è¯´æ˜
        params_info = "\n".join([
            f"- {name}: {desc}"
            for name, desc in base_param_descriptions.items()
        ])

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªå‚æ•°å€¼æå–å™¨ã€‚è¯·ä»ä»¥ä¸‹ä¸Šä¸‹æ–‡ä¸­ï¼Œå°½å¯èƒ½æå–å‡ºä¸ç›®æ ‡å‚æ•°åŒ¹é…çš„å…·ä½“å€¼ã€‚

    è¦æ±‚ï¼š
    - åªæå–æ˜ç¡®æåŠæˆ–å¯åˆç†æ¨æ–­çš„å€¼ï¼›
    - å¦‚æœæŸä¸ªå‚æ•°æ— æ³•ç¡®å®šï¼Œä¸è¦çŒœæµ‹ï¼Œç›´æ¥è·³è¿‡ï¼›
    - è¾“å‡ºå¿…é¡»æ˜¯ä¸¥æ ¼ JSON æ ¼å¼ï¼š{{ "å‚æ•°å": "æå–çš„å€¼" }}
    - å€¼å¿…é¡»æ˜¯å­—ç¬¦ä¸²ï¼›
    - ä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–æ–‡å­—ï¼ŒåŒ…æ‹¬è§£é‡Šã€markdownã€å‰ç¼€ã€‚

    ã€ç›®æ ‡å‚æ•°å®šä¹‰ã€‘
    {params_info}

    ã€å½“å‰ä¸Šä¸‹æ–‡ã€‘
    {current_context_str}
    """

        try:
            response = self.llm_client.generate(
                prompt=prompt,
                parse_json=True,
            )
            # text = response.output.text.strip()

            # æå– JSON
            # json_match = re.search(r"\{.*\}", text, re.DOTALL)
            json_match = response
            if json_match:
                # extracted = json.loads(json_match.group(0))
                extracted = json_match  
                # åªä¿ç•™åˆæ³•å‚æ•°å + å­—ç¬¦ä¸²å€¼
                filled = {}
                for k, v in extracted.items():
                    if k in base_param_descriptions and isinstance(v, str) and v.strip():
                        filled[k] = v.strip()
            else:
                filled = {}
        except Exception as e:
            print(f"[WARN] LLM é¢„å¡«å……å¤±è´¥ï¼Œè·³è¿‡: {e}")
            filled = {}

        # åˆ†ç¦»å·²å¡«å……å’Œå‰©ä½™å‚æ•°
        remaining = {
            k: v for k, v in base_param_descriptions.items()
            if k not in filled
        }

        return filled, remaining
    



    # ----------------------------------------------------------
    # è¾…åŠ©åŠŸèƒ½
    # ----------------------------------------------------------

    def extract_context(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """ä¿ç•™åŸæœ‰åŸºç¡€æå–é€»è¾‘"""
        base_ctx = {}
        fields = ['task_id', 'task_type', 'user_id', 'content', 'query', 'payload']
        for f in fields:
            if f in task_data:
                base_ctx[f] = task_data[f]
        return base_ctx

    def register_context_template(self, name: str, template: Dict) -> None:
        self.context_templates[name] = template

    def enrich_context_from_result(
        self, 
        msg: 'TaskMessage', 
        result: Any, 
        task_name: str = ""
    ) -> None:
        """
        ä»ä»»åŠ¡æ‰§è¡Œç»“æœä¸­å¯Œé›†ä¸Šä¸‹æ–‡
        
        Args:
            msg: TaskMessage å¯¹è±¡ï¼ŒåŒ…å«ä¸Šä¸‹æ–‡ä¿¡æ¯
            result: ä»»åŠ¡æ‰§è¡Œç»“æœ
            task_name: ä»»åŠ¡åç§°ï¼ˆå¯é€‰ï¼‰
        """
        # ç¤ºä¾‹ï¼šä» result ä¸­æå–ç»“æ„åŒ–å­—æ®µ
        if isinstance(result, dict):
            for key, value in result.items():
                # è‡ªå®šä¹‰è¿‡æ»¤é€»è¾‘ï¼šåªä¿ç•™åŸºæœ¬ç±»å‹å’Œéç©ºå€¼
                if value is not None and isinstance(value, (str, int, float, bool, list, dict)):
                    # ç”Ÿæˆå®‰å…¨é”®åï¼ŒåŒ…å«ä»»åŠ¡è·¯å¾„å‰ç¼€
                    safe_key = f"{msg.task_path.replace('/', '_')}.{key}"
                    msg.enriched_context[safe_key] = value
        elif isinstance(result, (list, tuple)):
            # å¤„ç†åˆ—è¡¨ç»“æœï¼Œæ·»åŠ ç´¢å¼•
            for i, item in enumerate(result[:10]):  # æœ€å¤šå–å‰10ä¸ªå…ƒç´ 
                if isinstance(item, dict):
                    for key, value in item.items():
                        if value is not None and isinstance(value, (str, int, float, bool)):
                            safe_key = f"{msg.task_path.replace('/', '_')}.item_{i}.{key}"
                            msg.enriched_context[safe_key] = value
        elif isinstance(result, (str, int, float, bool)):
            # å¤„ç†å•ä¸ªåŸºæœ¬ç±»å‹ç»“æœ
            safe_key = f"{msg.task_path.replace('/', '_')}.result"
            msg.enriched_context[safe_key] = result

    def extract_params_for_capability(
        self, 
        capability: str, 
        enriched_context: Dict[str, Any], 
        global_context: Dict[str, Any]
    ) -> Tuple[Dict[str, Any], List[str]]:
        """
        ä¸ºç‰¹å®šèƒ½åŠ›æ™ºèƒ½æå–å‚æ•°
        
        Args:
            capability: èƒ½åŠ›åç§°
            enriched_context: å¯Œä¸Šä¸‹æ–‡
            global_context: å…¨å±€ä¸Šä¸‹æ–‡
            
        Returns:
            (å¯ç”¨å‚æ•°, ç¼ºå¤±å‚æ•°åˆ—è¡¨)
        """
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„ CAPABILITY_SPECS è¿›è¡Œå®ç°
        # ç¤ºä¾‹å®ç°ï¼šåŸºäºç®€å•çš„å‚æ•°æ˜ å°„
        spec = self._get_capability_spec(capability)
        if not spec:
            return {}, []
            
        params = {}
        missing = []

        for param_name, config in spec["parameters"].items():
            found = False

            # 1. ä¼˜å…ˆä» enriched_context åŒ¹é…ï¼ˆæ”¯æŒåˆ«åï¼‰
            for alias in [param_name] + config.get("aliases", []):
                if alias in enriched_context:
                    params[param_name] = enriched_context[alias]
                    found = True
                    break

            # 2. å°è¯•ä» global_context è·å–ï¼ˆå¦‚ user_idï¼‰
            if not found and param_name in global_context:
                params[param_name] = global_context[param_name]
                found = True

            # 3. ä»ç¼ºå¤±ï¼Ÿ
            if not found:
                missing.append(param_name)

        return params, missing
    
    def _get_capability_spec(self, capability: str) -> Optional[Dict[str, Any]]:
        """
        è·å–èƒ½åŠ›çš„å‚æ•°è§„æ ¼
        
        Args:
            capability: èƒ½åŠ›åç§°
            
        Returns:
            èƒ½åŠ›è§„æ ¼å­—å…¸ï¼ŒåŒ…å« parameters å­—æ®µ
        """
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…ç³»ç»Ÿä¸­çš„èƒ½åŠ›è§„æ ¼è¿›è¡Œå®ç°
        # ç¤ºä¾‹ï¼šè¿”å›ä¸€ä¸ªç®€å•çš„é»˜è®¤è§„æ ¼
        return {
            "parameters": {
                # é»˜è®¤å‚æ•°è§„æ ¼ï¼Œå®é™…ç³»ç»Ÿä¸­åº”è¯¥ä»é…ç½®æˆ–æ³¨å†Œä¸­å¿ƒè·å–
                "query": {"aliases": ["q", "question", "prompt"]},
                "user_id": {"aliases": ["uid", "user"]},
                "tenant_id": {"aliases": ["tid", "tenant"]}
            }
        }